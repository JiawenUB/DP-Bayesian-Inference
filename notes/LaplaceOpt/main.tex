\documentclass{article}
\usepackage{caption}

\input{macros}
\usepackage{accents}

\begin{document}
\title{Optimality of Laplace Mechanism}

\author{Jiawen \textsc{Liu}} % Author name

\maketitle

\section{Laplace Mechanism with Post-Processing}

\begin{algorithm}
  \caption{$\lapmech$}
  \label{lapmech}
  \begin{algorithmic}
  	\REQUIRE $\dataobs \in \{0 ,1 \}^n$
	\STATE \quad apply the Bayesian inference algorithm on $\dataobs'$, get true posterior $\betad(\valpha)$
  	\STATE \quad {\bf let} $p = \uniform{0}{1}$, $\eta \sim \lap{0}{\frac{1.0}{\epsilon}}$
  	\STATE \quad {\bf If} $p >0.5$: 
  	\STATE \quad \quad with 0.5 probability adding noise to first component.
  	\STATE \quad \quad  $\dataobs' = (\lfloor \text{x}_1 + \mu \rfloor_0^n, n - \lfloor \text{x}_1 + \mu \rfloor_0^n)$ 
  	\STATE \quad {\bf Else}: 
  	\STATE \quad \quad with 0.5 probability adding noise to second component.
  	\STATE \quad \quad  $\dataobs' = (n - \lfloor \text{x}_2 + \mu \rfloor_0^n, \lfloor \text{x}_2 + \mu \rfloor_0^n)$ 
	\STATE \quad apply the Bayesian inference algorithm on $\dataobs'$, get: $\betad(\valpha')$
	\RETURN $\valpha'$
  \end{algorithmic}
\end{algorithm}



\clearpage
\section{Laplace Mechanism Accuracy Analysis}
\label{sec_fullacc}

\begin{table}[htbp]
	\tiny
	\centering
	\caption{Accuracy with $n = 2, \epsilon = 1.0$}
	\label{tab_n2eps1.0prob}
	\vspace{-0.2cm}
\begin{tabular}{|c||r|r|r|r|r|r|r|r|r|}
	\hline

	\multirow{3}{*}{True data ($\dataobs$)} 	
								&  \multicolumn{9}{c|}{Noised Results ($\dataobs'$)}  		
								\\ \cline{2-10}
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (0, 2)]$}  	
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (1, 1)]$} 	
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (2, 0)]$} 	\\
	                      		\cline{2-10}
						        & $\ilapmech$	
								& $\lapmech$
								& $\hexpmech$
								& $\ilapmech$
								& $\lapmech$	
								& $\hexpmech$
								& $\ilapmech$
								& $\lapmech$
								& $\hexpmech$\\
	                      		\hline \hline
	$\dataobs = (0,2)$          & 0.658030
								& 0.598367
								& 0.413430
								& 0.216166	
								& 0.158030
								& 0.321980
								& 0.125804
								& 0.243603	
								& 0.264590	
								\\  \hline
	$\dataobs = (1,1)$          & 0.341970
								& 0.401633	
								& 0.304504
								& 0.316060	
								& 0.196735	
								& 0.390991 
								& 0.341970
								& 0.401633	
								& 0.304504
								\\  \hline
	$\dataobs = (2,0)$          & 0.125804
								& 0.243603	
								& 0.264590
								& 0.216166
								& 0.158030
								& 0.321980
								& 0.658030	
								& 0.598367	
								& 0.413430	
								\\  \hline
\end{tabular}
\end{table}

\begin{figure*}[ht]
\begin{center}
\vspace{-0.5cm}
     \centering
     \subfigure[True data $(0,2)$]
     {
         \includegraphics[width=0.3\textwidth]{data[0-2]eps1.eps}
     }
     \subfigure[True data $(1,1)$]
     {
         \includegraphics[width=0.3\textwidth]{data[1-1]eps1.eps}
     }
     \subfigure[True data $(2,0)$]
     {
         \includegraphics[width=0.3\textwidth]{data[2-0]eps1.eps}
     }
      \caption{\footnotesize The probability of outputting each candidates with different true data and $\epsilon = 0.5$}
\end{center}
\end{figure*}

\begin{table}[htbp]
	\vspace{-0.8cm}
	\tiny
	\centering
	\caption{\footnotesize Accuracy with $n = 2, \epsilon = 0.5$}
	\label{tab_n2eps0.5prob}
	\vspace{-0.2cm}
\begin{tabular}{|c||r|r|r|r|r|r|r|r|r|}
	\hline

	\multirow{3}{*}{True data ($\dataobs$)} 	
								&  \multicolumn{9}{c|}{Noised Results ($\dataobs'$)}  		
								\\ \cline{2-10}
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (0, 2)]$}  	
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (1, 1)]$} 	
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (2, 0)]$} 	\\
	                      		\cline{2-10}
						        & $\ilapmech$	
								& $\lapmech$
								& $\hexpmech$
								& $\ilapmech$
								& $\lapmech$	
								& $\hexpmech$
								& $\ilapmech$
								& $\lapmech$
								& $\hexpmech$\\
	                      		\hline \hline
	$\dataobs = (0,2)$          & 0.598367
								& 0.555300
								& 0.372788
								& 0.158030
								& 0.098367	
								& 0.328984 
								& 0.243603
								& 0.346333
								& 0.298227
								\\  \hline
	$\dataobs = (1,1)$          & 0.401633
								& 0.444700
								& 0.319168
								& 0.196735
								& 0.110600
								& 0.361664
								& 0.401632
								& 0.444700
								& 0.319167
								\\  \hline
	$\dataobs = (2,0)$          & 0.243603
								& 0.346333
								& 0.298227
								& 0.158030
								& 0.098367	
								& 0.328984 
								& 0.598367
								& 0.555300
								& 0.372788
								\\  \hline
\end{tabular}
\end{table}

\begin{figure*}[ht]
\begin{center}
\vspace{-0.5cm}
     \centering
     \subfigure[True data $(0,2)$]
     {
         \includegraphics[width=0.3\textwidth]{data[0-2]eps0-5.eps}
     }
     \subfigure[True data $(1,1)$]
     {
         \includegraphics[width=0.3\textwidth]{data[1-1]eps0-5.eps}
     }
     \subfigure[True data $(2,0)$]
     {
         \includegraphics[width=0.3\textwidth]{data[2-0]eps0-5.eps}
     }
      \caption{\footnotesize The probability of outputting candidates with different true data and $\epsilon = 0.5$}
\vspace{-0.5cm}
\end{center}
\end{figure*}


\begin{table}[htbp]
	\tiny
	\centering
	\caption{Accuracy with $n = 2, \epsilon = 0.1$}
	\label{tab_n2eps0.1prob}
\begin{tabular}{|c||r|r|r|r|r|r|r|r|r|}
	\hline
	\multirow{3}{*}{True data ($\dataobs$)}
								&  \multicolumn{9}{c|}{Noised Results ($\dataobs'$)}
								\\ \cline{2-10}
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (0, 2)]$}  	
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (1, 1)]$} 	
	                      		&  \multicolumn{3}{c|}{$\Pr[\dataobs' = (2, 0)]$} 	\\
	                      		\cline{2-10}
						        & $\ilapmech$	
								& $\lapmech$
								& $\hexpmech$
								& $\ilapmech$
								& $\lapmech$	
								& $\hexpmech$
								& $\ilapmech$
								& $\lapmech$
								& $\hexpmech$\\
	                      		\hline \hline
	$\dataobs = (0,2)$          & 0.5237906	
								& 0.5121926	
								& 0.3411036
								& 0.0453173
								& 0.0237906
								& 0.3326818
								& 0.430892
								& 0.464017
								& 0.326215
								\\  \hline
	$\dataobs = (1,1)$          & 0.4762094
								& 0.4878074
								& 0.3305441
								& 0.0475813
								& 0.0243853
								& 0.3389119 
								& 0.4762094
								& 0.4878074	
								& 0.3305441	
								\\  \hline
	$\dataobs = (2,0)$          & 0.430892
								& 0.464017
								& 0.326215
								& 0.0453173
								& 0.0237906
								& 0.3326818 
								& 0.5237906	
								& 0.5121926	
								& 0.3411036
								\\  \hline
\end{tabular}
\end{table}

\begin{figure*}[ht]
\begin{center}
\vspace{-0.5cm}
     \centering
     \subfigure[True data $(0,2)$]
     {
         \includegraphics[width=0.3\textwidth]{data[0-2]eps0-1.eps}
     }
     \subfigure[True data $(1,1)$]
     {
         \includegraphics[width=0.3\textwidth]{data[1-1]eps0-1.eps}
     }
     \subfigure[True data $(2,0)$]
     {
         \includegraphics[width=0.3\textwidth]{data[2-0]eps0-1.eps}
     }
      \caption{\footnotesize The probability of outputting candidates with different true data and $\epsilon = 0.1$}
\vspace{-0.5cm}
\end{center}
\end{figure*}


\begin{table}[htbp]
\vspace{-0.8cm}
	\scriptsize
	\centering
	\caption{Error (Hellinger Distance) Between Noised Posterior and True Posterior with $n = 2, \epsilon = 1.0$, prior: $\betad(1,1)$}
	\label{tab_n2error}
\vspace{-0.2cm}
\begin{tabular}{|c||r|r|r|}
	\hline
	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{3}{c|}{$\hellinger(\betad(\valpha), \betad(\valpha'))$}
								\\ \cline{2-4}
	                      		& $\dataobs' = (0, 2)$
	                      		& $\dataobs' = (1, 1)$
	                      		& $\dataobs' = (2, 0)$
	                      		\\  \hline \hline
	$\dataobs = (0,2)$          & 0.0	
								& 0.351365939808
								& 0.627271345023 
								\\  \hline
	$\dataobs = (1,1)$          & 0.351365939808
								& 0.0			
								& 0.351365939808
								\\  \hline
	$\dataobs = (2,0)$          & 0.627271345023
								& 0.351365939808
								& 0.0
								\\  \hline
\end{tabular}
\end{table}


\clearpage
The following tables are with data size $n = 3:$



\begin{table}[htbp]
	\footnotesize
	\centering
	\caption{Accuracy of $\ilapmech$ with $n = 3, \epsilon = 1.0$}
	\label{tab_n3eps1prob}
\begin{tabular}{|c||r|r|r|r|}
	\hline
	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{4}{c|}{Noised Results ($\dataobs'$)}  
								\\ \cline{2-5}
	                      		&  $\Pr[\dataobs' = (0, 3)]$  	
	                      		&  $\Pr[\dataobs' = (1, 2)]$ 	
	                      		&  $\Pr[\dataobs' = (2, 1)]$ 	
	                      		&  $\Pr[\dataobs' = (3, 0)]$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,3)$          & {\bf 0.658030140}
								& {\bf 0.216166179}
								&  0.0795230932009
								&  0.0462805879011
								\\  \hline
	$\dataobs = (1,2)$          & {\bf 0.341969860}
								& {\bf 0.316060279}
								& {\bf 0.216166179}
								&  0.125803681
								\\  \hline
	$\dataobs = (2,1)$          & 0.125803681
								& {\bf 0.216166179}
								& {\bf 0.316060279}
								& {\bf 0.341969860}
								\\  \hline
	$\dataobs = (3,0)$          & 0.0462805879
								& 0.0795230932	
								& {\bf 0.216166179}
								& {\bf 0.658030140}
								\\  \hline
\end{tabular}
\end{table}

\begin{table}[htbp]
	\footnotesize
	\centering
	\caption{Accuracy of $\lapmech$ with $n = 3, \epsilon = 1.0$}
	\label{tab_n3eps1prob_lap}
\begin{tabular}{|c||r|r|r|r|}
	\hline
	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{4}{c|}{Noised Results ($\dataobs'$)}  
								\\ \cline{2-5}
	                      		&  $\Pr[\dataobs' = (0, 3)]$  	
	                      		&  $\Pr[\dataobs' = (1, 2)]$ 	
	                      		&  $\Pr[\dataobs' = (2, 1)]$ 	
	                      		&  $\Pr[\dataobs' = (3, 0)]$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,3)$          & 0.598367335
								& 0.158030140	
								& 0.095850125
								& 0.147752400
								\\  \hline
	$\dataobs = (1,2)$          & 0.40163266
								& 0.19673467
								& 0.15803013
								& 0.24360252
								\\  \hline
	$\dataobs = (2,1)$          & 0.24360252
								& 0.15803013
								& 0.19673467
								& 0.40163266
								\\  \hline
	$\dataobs = (3,0)$          & 0.147752400
								& 0.095850125	
								& 0.158030140
								& 0.598367335
								\\  \hline
\end{tabular}
\end{table}

\begin{table}[htbp]
	\footnotesize
	\centering
	\caption{Accuracy of $\hexpmech$ with $n = 3, \epsilon = 1.0$}
	\label{tab_n3eps1prob_exp}
\begin{tabular}{|c||r|r|r|r|}
	\hline
	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{4}{c|}{Noised Results ($\dataobs'$)}  
								\\ \cline{2-5}
	                      		&  $\Pr[\dataobs' = (0, 3)]$  	
	                      		&  $\Pr[\dataobs' = (1, 2)]$ 	
	                      		&  $\Pr[\dataobs' = (2, 1)]$ 	
	                      		&  $\Pr[\dataobs' = (3, 0)]$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,3)$          & 0.335390398
								& 0.261202304
								& 0.217281854
								& 0.186125444
								\\  \hline
	$\dataobs = (1,2)$          & 0.241155567
								& 0.309649877
								& 0.248588637
								& 0.200605920
								\\  \hline
	$\dataobs = (2,1)$          & 0.200605920
								& 0.248588637
								& 0.309649877
								& 0.241155567
								\\  \hline
	$\dataobs = (3,0)$          & 0.186125444
								& 0.217281854
								& 0.261202304
								& 0.335390398
								\\  \hline
\end{tabular}
\end{table}


\begin{figure*}[ht]
\begin{center}
\vspace{-0.5cm}
     \centering
     \subfigure[True data $(0,3)$]
     {
         \includegraphics[width=0.4\textwidth]{data[0-3]eps1.eps}
     }
     \subfigure[True data $(1,2)$]
     {
         \includegraphics[width=0.4\textwidth]{data[1-2]eps1.eps}
     }
     \subfigure[True data $(2,1)$]
     {
         \includegraphics[width=0.4\textwidth]{data[2-1]eps1.eps}
     }
     \subfigure[True data $(3,0)$]
     {
         \includegraphics[width=0.4\textwidth]{data[3-0]eps1.eps}
     }
      \caption{\footnotesize The probability of outputting candidates with different true data and $\epsilon = 1.0$, representing same statics as the Table \ref{tab_n3eps1prob}, \ref{tab_n3eps1prob_lap}, \ref{tab_n3eps1prob_exp}}
\vspace{-0.5cm}
\end{center}
\end{figure*}



\begin{table}[htbp]
	\centering
	\small
	\caption{Error (Hellinger Distance) with $n = 3, \epsilon = 1.0$, prior: $\betad(1,1)$}
	\label{tab_n3error}
\begin{tabular}{|c||r|r|r|r|}
	\hline

	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{4}{c|}
								{$\hellinger(\betad(\valpha), \betad(\valpha'))$}  
								\\ \cline{2-5}
	                      		&  $\dataobs' = (0, 3)$  	
	                      		&  $\dataobs' = (1, 2)$ 	
	                      		&  $\dataobs' = (2, 1)$ 	
	                      		&  $\dataobs' = (3, 0)$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,3)$          & 0.0	
								& 0.30968268033	
								& 0.537732813886
								& 0.72945673866
								\\  \hline
	$\dataobs = (1,2)$          & 0.309682680332
								& 0.0
								& 0.272078233285
								& 0.537732813886
								\\  \hline
	$\dataobs = (2,1)$          & 0.537732813886
								& 0.272078233285			
								& 0.0
								& 0.309682680332
								\\  \hline
	$\dataobs = (3,0)$          & 0.72945673866
								& 0.537732813886 			
								& 0.309682680332
								& 0.0
								\\  \hline
\end{tabular}
\end{table}



\clearpage
$n = 4:$
\begin{table}[htbp]
	\scriptsize
	\centering
	\caption{Accuracy of $\ilapmech$ with $n = 4, \epsilon = 1.0$}
	\label{tab_n4eps1prob_ilap}
\begin{tabular}{|c||r|r|r|r|r|}
	\hline

	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{5}{c|}{Noised Results ($\dataobs'$)}  
								\\ \cline{2-6}
	                      		&  $\Pr[\dataobs' = (0, 4)]$  	
	                      		&  $\Pr[\dataobs' = (1, 3)]$ 	
	                      		&  $\Pr[\dataobs' = (2, 2)]$ 	
	                      		&  $\Pr[\dataobs' = (3, 1)]$ 	
	                      		&  $\Pr[\dataobs' = (4, 0)]$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,4)$          & {\bf 0.658030139707}	
								& {\bf 0.216166179191}	
								&  0.0795230932009
								&  0.029254911087
								&  0.0170256768141
								\\  \hline
	$\dataobs = (1,3)$          & {\bf 0.341969860293}	
								& {\bf 0.316060279414}			
								& {\bf 0.216166179191}
								&  0.0795230932009
								&  0.0462805879011
								\\  \hline
	$\dataobs = (2,2)$          & 0.125803681102
								& {\bf 0.216166179191}			
								& {\bf 0.316060279414}
								& {\bf 0.216166179191} 
								&  0.125803681102
								\\  \hline
	$\dataobs = (3,1)$          & 0.0462805879011
								& 0.0795230932009 			
								& {\bf 0.216166179191}
								& {\bf0.316060279414} 
								&  0.341969860293
								\\  \hline
	$\dataobs = (4,0)$          & 0.017025676814
								& 0.029254911087
								& {\bf 0.0795230932009}
								& {\bf 0.216166179191} 
								&  0.658030139707
								\\  \hline
\end{tabular}
\vspace{-0.5cm}
\end{table}

\begin{table}[htbp]
	\scriptsize
	\centering
	\caption{Accuracy of $\lapmech$ with $n = 4, \epsilon = 1.0$}
	\label{tab_n4eps1prob_lap}
\begin{tabular}{|c||r|r|r|r|r|}
	\hline

	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{5}{c|}{Noised Results ($\dataobs'$)}  
								\\ \cline{2-6}
	                      		&  $\Pr[\dataobs' = (0, 4)]$  	
	                      		&  $\Pr[\dataobs' = (1, 3)]$ 	
	                      		&  $\Pr[\dataobs' = (2, 2)]$ 	
	                      		&  $\Pr[\dataobs' = (3, 1)]$ 	
	                      		&  $\Pr[\dataobs' = (4, 0)]$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,4)$          & 0.598367335
								& 0.158030140	
								& 0.095850125
								& 0.058136040
								& 0.089616361
								\\  \hline
	$\dataobs = (1,3)$          & 0.401632665
								& 0.196734670
								& 0.158030140
								& 0.095850125
								& 0.147752400
								\\  \hline
	$\dataobs = (2,2)$          & 0.243602525
								& 0.158030140
								& 0.196734670
								& 0.158030140
								& 0.243602525
								\\  \hline
	$\dataobs = (3,1)$          & 0.147752400
								& 0.095850125
								& 0.158030140
								& 0.196734670
								& 0.401632665
								\\  \hline
	$\dataobs = (4,0)$          & 0.089616361
								& 0.058136040
								& 0.095850125
								& 0.158030140
								& 0.598367335
								\\  \hline
\end{tabular}
\vspace{-0.5cm}
\end{table}

\begin{table}[htbp]
	\scriptsize
	\centering
	\caption{Accuracy of $\hexpmech$ with $n = 4, \epsilon = 1.0$}
	\label{tab_n4eps1prob_exp}
\begin{tabular}{|c||r|r|r|r|r|}
	\hline

	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{5}{c|}{Noised Results ($\dataobs'$)}  
								\\ \cline{2-6}
	                      		&  $\Pr[\dataobs' = (0, 4)]$  	
	                      		&  $\Pr[\dataobs' = (1, 3)]$ 	
	                      		&  $\Pr[\dataobs' = (2, 2)]$ 	
	                      		&  $\Pr[\dataobs' = (3, 1)]$ 	
	                      		&  $\Pr[\dataobs' = (4, 0)]$ 	
	                      		\\  \hline
	                      		\hline
	$\dataobs = (0,4)$          & 0.28639286
								& 0.22304298
								& 0.18648505
								& 0.16144157
								& 0.14263753
								\\  \hline
	$\dataobs = (1,3)$          & 0.20339335
								& 0.26116223
								& 0.21220610
								& 0.17601942
								& 0.14721890
								\\  \hline
	$\dataobs = (2,2)$          & 0.15904127
								& 0.20764682
								& 0.26662381
								& 0.20764683
								& 0.15904127
								\\  \hline
	$\dataobs = (3,1)$          & 0.14721890
								& 0.17601942
								& 0.21220610
								& 0.26116223
								& 0.20339335
								\\  \hline
	$\dataobs = (4,0)$          & 0.14263753
								& 0.16144157
								& 0.18648505
								& 0.22304298
								& 0.28639286
								\\  \hline
\end{tabular}
\vspace{-0.5cm}
\end{table}

\begin{figure*}[ht]
\begin{center}
\vspace{-0.5cm}
     \centering
     \subfigure[True data $(0,4)$]
     {
         \includegraphics[width=0.3\textwidth]{data[0-4]eps1.eps}
     }
     \subfigure[True data $(1,3)$]
     {
         \includegraphics[width=0.3\textwidth]{data[1-3]eps1.eps}
     }
     \subfigure[True data $(2,2)$]
     {
         \includegraphics[width=0.3\textwidth]{data[2-2]eps1.eps}
     }
     \subfigure[True data $(3,1)$]
     {
         \includegraphics[width=0.3\textwidth]{data[3-1]eps1.eps}
     }
     \subfigure[True data $(4,0)$]
     {
         \includegraphics[width=0.3\textwidth]{data[3-1]eps1.eps}
     }
      \caption{\footnotesize The probability of outputting candidates with different true data and $\epsilon = 1.0$, representing same statics as the Table \ref{tab_n4eps1prob_ilap}, \ref{tab_n4eps1prob_lap}, \ref{tab_n4eps1prob_exp}}
\vspace{-0.5cm}
\end{center}
\end{figure*}


\begin{table}[htbp]
	\scriptsize
	\centering
	\caption{Error (Hellinger Distance) with $n = 4, \epsilon = 1.0$, prior: $\betad(1,1)$}
	\label{tab_n4error}
\begin{tabular}{|c||r|r|r|r|r|}
	\hline

	\multirow{2}{*}{True data ($\dataobs$)}
								& \multicolumn{5}{c|}
								{$\hellinger(\betad(\valpha), \betad(\valpha'))$}  
								\\ \cline{2-6}
								&  $\dataobs' = (0, 4)$  	
								&  $\dataobs' = (1, 3)$ 	
								&  $\dataobs' = (2, 2)$ 	
								&  $\dataobs' = (3, 1)$ 	
								&  $\dataobs' = (4, 0)$ 	
								\\  \hline
	 							\hline
	$\dataobs = (0,4)$			&	0.0	
								&	0.285148545618
								&	0.489330216753
								&	0.65381277487
								&	0.795060097621
								\\  \hline
	$\dataobs = (1,3)$          &	0.285148545618
								&	0.0
								&	0.236768870388
								&	0.45001855566
								&	0.65381277487
								\\  \hline
	$\dataobs = (2,2)$          &	0.489330216753
								&	0.236768870388			
								&	0.0
								&	0.236768870388
								&	0.489330216753
								\\  \hline
	$\dataobs = (3,1)$          &	0.65381277487
								&	0.45001855566			
								&	0.236768870388
								&	0.0
								&	0.285148545618
								\\  \hline
	$\dataobs = (4,0)$          &	0.795060097621
								&	0.65381277487 			
								&	0.489330216753
								&	0.285148545618
								&	0.0
								\\  \hline
\end{tabular}
\vspace{-0.5cm}
\end{table}


\clearpage
Some observations

{\small

\noindent $n = 2:$
\[
\Pr[\hlg(\bysinfer{\dataobs}, \ilapmech(\dataobs)) < 0.35137 ~ = LS(x)]
\geq \begin{cases}
	0.87	& \dataobs = (0, 2)\\
%
	1.0		& \dataobs = (1, 1)\\
%
	0.87	& \dataobs = (2, 0)\\
\end{cases}.
\]


\noindent $n = 3:$
\[
\Pr[\hlg(\bysinfer{\dataobs}, \ilapmech(\dataobs)) < 0.30968 ~ = LS(x)]
\geq \begin{cases}
 	0.87
	& \dataobs = (0, 3)\\
%
 	0.87
	& \dataobs = (1, 2)\\
%
 	0.87
	& \dataobs = (2, 1)\\
%
	0.87
	& \dataobs = (3, 0)
\end{cases}.
\]

\noindent $n = 4:$
\[
\Pr[\hlg(\bysinfer{\dataobs}, \ilapmech(\dataobs)) < 0.2851 ~ = LS(x)]
\geq 
\begin{cases}
 	0.87
	& \dataobs = (0, 4)\\
%
 	0.87
	& \dataobs = (1, 3)\\
%
	0.87
	& \dataobs = (3, 1)\\
%
	0.87
	& \dataobs = (4, 0)
\end{cases}.
\]

\[
\Pr[\hlg(\bysinfer{\dataobs}, \ilapmech(\dataobs)) < 0.2368 ~ = LS(x)]
\geq
\begin{cases}
0.74 & \dataobs = (2, 2)
\end{cases}
\]




$\dots$

\begin{thm}
To prove the optimality of Laplace mechanism, we are showing 
\[
\frac{ELap(\dataobs)}{(\epsilon \times LS(\dataobs))}
\]
is $O(1)$, considering $n=|\dataobs| \geq 2$ being the parameter.

Where $LS(\cdot)$ is the local sensitivity, and where $ELap(\cdot)$ is the measure of the error of the Laplace mechanism, defined in this way:
\[
ELap(\dataobs) = \arg\big( \min\limits_{t}\{Pr[\hlg(\bysinfer{\dataobs}, \ilapmech(\dataobs))< t] >= 0.748\} \big).
\]
\end{thm}

\begin{proof}
From the calculation above, we can conclude that the $ELap(\dataobs) = LS(\dataobs)$, under the case $\epsilon = 1$\\
Then $\frac{ELap(\dataobs)}{(\epsilon \times LS(\dataobs))} = \frac{ELap(\dataobs)}{(LS(\dataobs))} = 1 = O(1)$.

Given data set $\dataobs = (a,b)$ of size $ n = a + b \geq 2$, when apply the Laplace noise on it, we get the noised results $\dataobs'$. The probability that $\dataobs' = (a,b)$ or $(a + 1, b-1)$ or $(a - 1, b + 1)$ is:


Simplified: (The full calculation is in Appendix)
{\footnotesize
\begin{equation}
\label{eq:proofbound1}
\begin{cases}
 	0.5 \times 
 	(\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}])
	= 0.8742
	& a = 0,	b = n\\
%
 	0.5 \times 
 	(\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}])
 	= 0.8742
	& a = 1,	b = n - 1, n \geq 3\\
%
	1
	& a = 1, b = 1\\
%
 	0.5 \times 
 	(\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}] 
 	+ 	
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}		<	2])
	= 0.8742
	& a = n - 1,	b = 1, n \geq 3\\
%
 	0.5 \times 
 	(\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}] 
 	+ 	
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}		<	2])
	= 0.8742
%
	& a = n,b = 0\\
 	0.5 \times 
 	(\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2])
	= 0.74839
	& o.w.
%
\end{cases}.
\end{equation}
}

By definition of adjacent data set, we know $\adj{\dataobs}{\dataobs'}$.\\
By definition of local sensitivity, we have:
\[
LS(\dataobs) = \max\limits_{\adj{\dataobs}{\dataobs''}}\hlg(\bysinfer{\dataobs},\bysinfer{\dataobs''})
\]
i.e., $\hlg(\bysinfer{\dataobs},\bysinfer{\dataobs'}) \leq LS(\dataobs)$.\\
Then, we can get:
\[
Pr[\hlg(\bysinfer{\dataobs}, \ilapmech(\dataobs)) < LS(\dataobs)] >= 0.748.
\]
Since the three $\dataobs'$ we are looking into is already the 3 nearest data set, so Hellinger distance between them are already the minimum distances. So, we can get: $ELap(\dataobs) = LS(\dataobs)$.\\
\[
\frac{ELap(\dataobs)}{(\epsilon*LS(\dataobs))} = \frac{1}{\epsilon} = O(1)
\]


\end{proof}
\begin{thm}
In order to prove the optimality of Laplace mechanism, instead of prove
$\frac{ELap(\dataobs)}{(\epsilon \times LS(\dataobs))}$ is $O(1)$, we prove a constant upper bound on following equations:
\[
\begin{array}{ll}
	 &	\frac{\arg\min\limits_{t}\{\Pr[\hlg(\betad(\alpha, \beta), \ilapmech(\dataobs))< t] >= 1 - \gamma\}}
	 	{	LS(\dataobs)	}\\
\leq &	\frac{\max\limits_{|t| \leq \frac{\lg(\frac{1}{\gamma})}{\epsilon}}
		\hlg(\betad(\alpha, \beta), \betad(\alpha + t, n - \lfloor \alpha + t \rfloor))}
		{	LS(\dataobs)	}\\
\leq & 	O(\frac{\lg{\frac{1}{\gamma}}}{\epsilon})
\end{array}
\]
where $\betad(\alpha, \beta) = \bysinfer{\dataobs} $.\\
Or following limitations, $\forall \rho \in (0,1), \forall M \in \mathbb{N}$:
\[
\lim\sup\limits_{n \rightarrow \infty} \frac{\hlg(\betad(\rho n, (1 - \rho) n), \betad(\rho n + M, (1 - \rho) n - M))}{\hlg(\betad(\rho n, (1 - \rho) n), \betad(\rho n + 1, (1 - \rho) n - 1))}
\leq O(M)
\]
\end{thm}

\clearpage

\section*{Appendix}
The computation formula for each of the value of $\ilapmech$ in the Table \ref{tab_n2eps1.0prob} is

{\scriptsize
\noindent $\dataobs = (0,2):$
\[
\Pr[\dataobs']
= \begin{cases}
\begin{array}{ll}
 	& 0.5 \times 
 	\big(
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}			<	0] 
 	\big) \\
 	+ 	
 	& 0.5 \times 
 	\big(
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 
 	\Pr[	1 	< \lap{0}{\frac{1}{\epsilon}}] 
 	\big) 
\end{array} 
	& \dataobs' = (0, 2)\\
\begin{array}{ll}
 	0.5 \times 
 	\big(
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	\big)
 	+ 	
 	0.5 \times 
 	\big(
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	\big) 
\end{array}  
	& \dataobs' = (1, 1)\\
\begin{array}{ll}
 	& 0.5 \times 
 	\big(
 	\Pr[	2	<	\lap{0}{\frac{1}{\epsilon}}	<	3] 
 	+ 
 	\Pr[	3	<	\lap{0}{\frac{1}{\epsilon}}]
 	\big) \\
 	+ 	
 	& 0.5 \times 
 	\big(
 	\Pr[	-2	< \lap{0}{\frac{1}{\epsilon}}	<	-1] 
 	+ 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}			<	-2] 
 	\big) 
\end{array}  
& \dataobs' = (2, 0)
\end{cases}.
\]


\noindent $\dataobs = (1,1):$
\[
\Pr[\dataobs']
= \begin{cases}
\begin{array}{ll}
 	& 0.5 \times 
 	\big(
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}			<	-1] 
 	\big) \\
 	+ 	
 	& 0.5 \times 
 	\big(
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 
 	\Pr[	2 	< \lap{0}{\frac{1}{\epsilon}}] 
 	\big) 
\end{array} 
	& \dataobs' = (0, 2)\\
\begin{array}{ll}
 	0.5 \times 
 	\big(
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	\big)
 	+ 	
 	0.5 \times 
 	\big(
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	\big) 
\end{array}  
	& \dataobs' = (1, 1)\\
\begin{array}{ll}
 	& 0.5 \times 
 	\big(
 	\Pr[	1	<	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 
 	\Pr[	2	<	\lap{0}{\frac{1}{\epsilon}}]
 	\big) \\
 	+ 	
 	& 0.5 \times 
 	\big(
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}			<	-1] 
 	\big) 
\end{array}  
& \dataobs' = (2, 0)
\end{cases}.
\]

\noindent $\dataobs = (2,0):$
\[
\Pr[\dataobs']
= \begin{cases}
\begin{array}{ll}
 	& 0.5 \times 
 	\big(
 	\Pr[	-2	< \lap{0}{\frac{1}{\epsilon}}	<	-1] 
 	+ 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}			< 	-2] 
 	\big) \\
 	+ 	
 	& 0.5 \times 
 	\big(
 	\Pr[	2	< \lap{0}{\frac{1}{\epsilon}}	<	3] 
 	+ 
 	\Pr[	3	< \lap{0}{\frac{1}{\epsilon}}] 
 	\big) 
\end{array} 
	& \dataobs' = (0, 2)\\
\begin{array}{ll}
 	0.5 \times 
 	\big(
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	\big)
 	+ 	
 	0.5 \times 
 	\big(
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	\big) 
\end{array}  
	& \dataobs' = (1, 1)\\
\begin{array}{ll}
 	& 0.5 \times 
 	\big(
 	\Pr[	0	<	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 
 	\Pr[	1	<	\lap{0}{\frac{1}{\epsilon}}]
 	\big) \\
 	+ 	
 	& 0.5 \times 
 	\big(
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}			<	0] 
 	\big) 
\end{array}  
& \dataobs' = (2, 0)
\end{cases}.
\]
}

The computation formula for each of the value in the table. \ref{tab_n3eps1prob}:

{\small

\noindent $\dataobs = (0,3):$
\[
\Pr[\dataobs']
= \begin{cases}
	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}] 
%
	& \dataobs' = (0, 3)\\
%
 	0.5 \times 
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	0.5 \times 
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
%
	& \dataobs' = (1, 2)\\
%
 	0.5 \times 
 	\Pr[	2	<	\lap{0}{\frac{1}{\epsilon}}	<	3] 
 	+ 	
 	0.5 \times 
 	\Pr[	-2	< \lap{0}{\frac{1}{\epsilon}}	<	-1] 
%
	& \dataobs' = (2, 1)\\
%
 	0.5 \times 
 	\Pr[	3	<	\lap{0}{\frac{1}{\epsilon}}]
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-2] 
%
& \dataobs' = (3, 0)
\end{cases}.
\]


\noindent $\dataobs = (1,2):$
\[
\Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}] 
	& \dataobs' = (0, 3)\\
%
 	0.5 \times 
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
	& \dataobs' = (1, 2)\\
%
 	0.5 \times 
 	\Pr[	1	<	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	0.5 \times 
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
	& \dataobs' = (2, 1)\\
%
 	0.5 \times 
 	\Pr[	2	<	\lap{0}{\frac{1}{\epsilon}}] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-1] 
	& \dataobs' = (3, 0)
\end{cases}.
\]

\noindent $\dataobs = (2,1):$
\[
\Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-1]
 	+ 	
 	0.5 \times 
 	\Pr[	2	< \lap{0}{\frac{1}{\epsilon}}] 
%
	& \dataobs' = (0, 3)\\
%
 	0.5 \times 
 	\Pr[	-1	< \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}	<	2] 
%
	& \dataobs' = (1, 2)\\
%
 	0.5 \times 
 	\Pr[	0	<	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	< \lap{0}{\frac{1}{\epsilon}}	<	1] 
%
& \dataobs' = (2, 1)\\
%
 	0.5 \times 
 	\Pr[	1	<	\lap{0}{\frac{1}{\epsilon}}	] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	0] 
%
& \dataobs' = (3, 0)
\end{cases}.
\]



\noindent $\dataobs = (3,0):$
\[
\Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-2] 
 	+ 	
 	0.5 \times 
 	\Pr[	3	< \lap{0}{\frac{1}{\epsilon}}] 
	& \dataobs' = (0, 3)\\
%
 	0.5 \times 
 	\Pr[	-2	< \lap{0}{\frac{1}{\epsilon}}	<	-1] 
 	+ 	
 	0.5 \times 
 	\Pr[	2	< \lap{0}{\frac{1}{\epsilon}}	<	3] 
	& \dataobs' = (1, 2)\\
%
 	0.5 \times 
 	\Pr[	-1	<	\lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	< \lap{0}{\frac{1}{\epsilon}}	<	2] 
	& \dataobs' = (2, 1)\\
%
 	0.5 \times 
 	\Pr[	0	<	\lap{0}{\frac{1}{\epsilon}}	] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	1] 
	& \dataobs' = (3, 0)
\end{cases}.
\]
}

The computation formula for each of the value in Table. \ref{tab_n4eps1prob_ilap}
{\scriptsize

\[
\dataobs = (0,4): \Pr[\dataobs']
= \begin{cases}
	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}] 
%
	& \dataobs' = (0, 4)\\
%
 	0.5 \times 
 	\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	0.5 \times 
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	0] 
%
	& \dataobs' = (1, 3)\\
%
 	0.5 \times 
 	\Pr[	2	\leq	\lap{0}{\frac{1}{\epsilon}}	<	3] 
 	+ 	
 	0.5 \times 
 	\Pr[	-2	\leq \lap{0}{\frac{1}{\epsilon}}	<	-1] 
%
	& \dataobs' = (2, 2)\\
%
 	0.5 \times 
 	\Pr[	3	\leq	\lap{0}{\frac{1}{\epsilon}}	< 4]
 	+ 	
 	0.5 \times 
 	\Pr[	-3	\leq	\lap{0}{\frac{1}{\epsilon}}	<	-2] 
%
	& \dataobs' = (3, 1)\\
%
 	0.5 \times 
 	\Pr[	4	\leq	\lap{0}{\frac{1}{\epsilon}}]
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-3] 
%
	& \dataobs' = (4, 0)
\end{cases}.
\]

\[
(\dataobs = (1,3)) \Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}] 
	& \dataobs' = (0, 4)\\
%
 	0.5 \times 
 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}	<	1] 
	& \dataobs' = (1, 3)\\
%
 	0.5 \times 
 	\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	0.5 \times 
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	0] 
	& \dataobs' = (2, 2)\\
%
 	0.5 \times 
 	\Pr[	2	\leq	\lap{0}{\frac{1}{\epsilon}}	<	3] 
 	+ 	
 	0.5 \times 
 	\Pr[	-2	\leq	\lap{0}{\frac{1}{\epsilon}}	<	-1] 
	& \dataobs' = (3, 1)\\
 	0.5 \times 
 	\Pr[	3	\leq	\lap{0}{\frac{1}{\epsilon}}] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-2] 
	& \dataobs' = (4, 0)
\end{cases}.
\]



\[
(\dataobs = (2,2)) \Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-1]
 	+ 	
 	0.5 \times 
 	\Pr[	2	\leq \lap{0}{\frac{1}{\epsilon}}] 
%
	& \dataobs' = (0, 4)\\
%
 	0.5 \times 
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2] 
%
	& \dataobs' = (1, 3)\\
%
 	0.5 \times 
 	\Pr[	0	\leq	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}	<	1] 
%
& \dataobs' = (2, 2)\\
%
 	0.5 \times 
 	\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	0.5 \times 
 	\Pr[	-1 	\leq	\lap{0}{\frac{1}{\epsilon}}	<	0] 
%
& \dataobs' = (3, 1)\\
%
 	0.5 \times 
 	\Pr[	2	\leq	\lap{0}{\frac{1}{\epsilon}}	] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-1] 
%
& \dataobs' = (4, 0)
\end{cases}.
\]


\[
( \dataobs = (3,1) ) \Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-2] 
 	+ 	
 	0.5 \times 
 	\Pr[	3	\leq \lap{0}{\frac{1}{\epsilon}}] 
	& \dataobs' = (0, 4)\\
%
 	0.5 \times 
 	\Pr[	-2	\leq \lap{0}{\frac{1}{\epsilon}}	<	-1] 
 	+ 	
 	0.5 \times 
 	\Pr[	2	\leq \lap{0}{\frac{1}{\epsilon}}	<	3] 
	& \dataobs' = (1, 3)\\
%
 	0.5 \times 
 	\Pr[	-1	<	\lap{0}{\frac{1}{\epsilon}}		<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2] 
	& \dataobs' = (2, 2)\\
%
 	0.5 \times 
 	\Pr[	0	\leq	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	0.5 \times 
 	\Pr[	0	\leq	\lap{0}{\frac{1}{\epsilon}}	<	1] 
	& \dataobs' = (3, 1)\\
%
 	0.5 \times 
 	\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	0] 
%
& \dataobs' = (4, 0)
\end{cases}.
\]


\[
(\dataobs = (4,0)) \Pr[\dataobs']
= \begin{cases}
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	-3] 
 	+ 	
 	0.5 \times 
 	\Pr[	4	\leq \lap{0}{\frac{1}{\epsilon}}] 
	& \dataobs' = (0, 3)\\
%
 	0.5 \times 
 	\Pr[	-3	\leq \lap{0}{\frac{1}{\epsilon}}	<	-2] 
 	+ 	
 	0.5 \times 
 	\Pr[	3	\leq \lap{0}{\frac{1}{\epsilon}}	<	4] 
	& \dataobs' = (1, 3)\\
%
 	0.5 \times 
 	\Pr[	-2	\leq	\lap{0}{\frac{1}{\epsilon}}	<	-1] 
 	+ 	
 	0.5 \times 
 	\Pr[	2	\leq 	\lap{0}{\frac{1}{\epsilon}}	<	3] 
	& \dataobs' = (2, 2)\\
%
 	0.5 \times 
 	\Pr[	-1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	0.5 \times 
 	\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	2] 
	& \dataobs' = (3, 1)\\
%
 	0.5 \times 
 	\Pr[	0	\leq	\lap{0}{\frac{1}{\epsilon}}	] 
 	+ 	
 	0.5 \times 
 	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	1] 
%
& \dataobs' = (4, 0)
\end{cases}.
\]
}

Full calculation of Equation. \ref{eq:proofbound1}.
{\scriptsize
\[
\begin{cases}
\left\{
\begin{array}{lr}
 	&
	0.5 \times 
 	(\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	 	+ 	
 	 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}])\\
%
+	&
 	0.5 \times 
 	(\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2] 
 	 	+ 	
 	 \Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	0])\\
\end{array}
\right\}
	= 0.8742
	& a = 0,	b = n\\
%
\left\{
\begin{array}{lr}
 	&
 	0.5 \times 
 	(\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}])\\
%
+	&
 	0.5 \times 
 	(\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	 
 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}	<	1] )\\
%
+ 	&
 	0.5 \times 
 	(\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	 
 	\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	0])\\
\end{array}
\right\}
 	= 0.8742
	& a = 1,	b = n - 1, n \geq 3\\
%
	1
	& a = 1, b = 1\\
%
\left\{ 	
\begin{array}{lr}
	&
	0.5 \times
	(
	\Pr[-1 \leq \lap{0}{\frac{1}{\epsilon}}	< 	0]
	+
	\Pr[1 \leq \lap{0}{\frac{1}{\epsilon}}	< 	2]
	)\\
+	&
	0.5 \times
	(
	\Pr[0 \leq \lap{0}{\frac{1}{\epsilon}}	< 	1]
	+
	\Pr[0 \leq \lap{0}{\frac{1}{\epsilon}}	< 	1]
	)\\
+	&
	0.5 \times
	(
	\Pr[1 \leq \lap{0}{\frac{1}{\epsilon}}]
	+
	\Pr[\lap{0}{\frac{1}{\epsilon}} < 0])
\end{array}
\right\}
	= 0.8742
	& a = n - 1,	b = 1, n \geq 3\\
%
\left\{
\begin{array}{lr}
 	&
 	0.5 \times 
 	(\Pr[	-1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	2])\\
+	&
 	0.5 \times 
 	(\Pr[	0	\leq	\lap{0}{\frac{1}{\epsilon}}	] 
 	  	+ 
 	  	\Pr[	\lap{0}{\frac{1}{\epsilon}}	<	1]) 
\end{array}
\right\}
	= 0.8742
	& a = n,b = 0\\
%
\left\{
\begin{array}{lr}
 	&
 	0.5 \times 
 	(\Pr[	-1	\leq \lap{0}{\frac{1}{\epsilon}}	<	0] 
 	+ 	
 	\Pr[	1	\leq \lap{0}{\frac{1}{\epsilon}}	<	2])\\
%
+	&
 	0.5 \times 
 	(\Pr[	0	\leq	\lap{0}{\frac{1}{\epsilon}}	<	1] 
 	+ 	
 	\Pr[	0	\leq \lap{0}{\frac{1}{\epsilon}}	<	1])\\
%
+	&
 	0.5 \times 
 	(\Pr[	1	\leq	\lap{0}{\frac{1}{\epsilon}}	<	2] 
 	+ 	
 	\Pr[	-1 	\leq	\lap{0}{\frac{1}{\epsilon}}	<	0]) 
\end{array}
\right\}
	= 0.74839
	& o.w.\\
%
\end{cases}.
\]
}

\end{document}
