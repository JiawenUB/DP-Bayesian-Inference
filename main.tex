
\input{macros}

\title{\textbf{Notes of DP - Bayesian Inference}\\}
% \author{Jiawen \textsc{Liu}}
\date{\vspace{-10ex}}

\begin{document}
\maketitle

\section{Setting up}
\label{sec_setup}
The Bayesian inference process is denoted as $\bysinfer(x,prior)$ taking an observed data set $x \in \mathcal{X}^n$ and a prior distribution as input, outputting a posterior distribution $posterior$. For conciseness, when prior is given, we use $\bysinfer(x)$.

For now, we already have a prior distribution $prior$, an observed data set $x$.

\subsection{Exponential Mechanism with Global Sensitivity}
\label{subsec_emgs}

\subsubsection{Mechanism Set up}
In exponential mechanism, candidate set $R$ can be obtained by enumerating $y \in \mathcal{X}^n$, i.e.
\begin{equation*}
R = \{\bysinfer(y)\ |\ y \in \mathcal{X}^n\}.
\end{equation*}

Hellinger distance $\hlg$ is used here to score these candidates. The utility function:
\begin{equation}
\label{equ_utility}
u(x,r) = -\hlg(\bysinfer(x), r); r \in R.
\end{equation}

Exponential mechanism with global sensitivity selects and outputs a candidate $r \in R$ with probability proportional to $exp(\frac{\epsilon u(x,r)}{2 \Delta_{g}u})$:
\begin{equation*}
P[r] = \frac
{exp(\frac{\epsilon u(x,r)}{2 \Delta_{g}u})}
{\Sigma_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{g}u})},
\end{equation*}
where global sensitivity is calculated by:
\begin{equation*}
\Delta_{g}u = 
\max_{\{|x',y'| \leq 1;x',y'\in \mathcal{X}^n\}}\max_{\{r\in R\}}
|\hlg(\bysinfer(x'), r) - \hlg(\bysinfer(y'), r)|
\end{equation*}

% We use probability proportional to $exp(\frac{\epsilon u(x,r)}{\Delta_{g}u})$ rather than $exp(\frac{\epsilon u(x,r)}{2 \Delta_{g}u})$. Since $\hlg$ is monotonic, i.e. our utility function is monotonic. 

\subsubsection{Security Analysis}
It can be proved that exponential mechanism with global sensitivity is $\epsilon$-differentially private. We denote the $\bysinfer$ with privacy mechanism as $\privinfer$. For adjacent data set $||x,y||_1 = 1$:
\begin{equation*}
\begin{split}
\frac{P[\privinfer(x,u,R) = r]}{P[\privinfer(y,u,R) = r]}
& =\frac
{\frac
{exp(\frac{\epsilon u(x,r)}{2 \Delta_{g}u})}
{\Sigma_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{g}u})}}
{\frac
{exp(\frac{\epsilon u(y,r)}{2 \Delta_{g}u})}
{\Sigma_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{g}u})}} \\
& = \left(\frac
{exp(\frac{\epsilon u(x,r)}{2 \Delta_{g}u})}
{exp(\frac{\epsilon u(y,r)}{2 \Delta_{g}u})}
\right)
\cdot
\left(\frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{g}u})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{g}u})}
\right)\\
& = exp\left(\frac
{\epsilon (u(x,r) - u(y,r))}
{2 \Delta_{g}u}
\right)
\cdot
\left(\frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{g}u})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{g}u})}
\right)\\
& \leq
exp(\frac{\epsilon}{2}) \cdot exp(\frac{\epsilon}{2}) \cdot
\left(\frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{g}u})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{g}u})}
\right)\\
& = exp(\epsilon).
\end{split}
\end{equation*}

Then, $\frac{P[\privinfer(x,u,R) = r]}{P[\privinfer(y,u,R) = r]} \geq exp(-\epsilon)$ can be obtained by symmetry.


\subsection{Exponential Mechanism with Local Sensitivity}
\label{subsec_emls}
\subsubsection{Mechanism Set up}
Exponential mechanism with local sensitivity share the same candidate set and utility function as it with global sensitivity. This outputs a candidate $r \in R$ with probability proportional to $exp(\frac{\epsilon u(x,r)}{2 \Delta_{l}u})$:
\begin{equation*}
P[r] = \frac
{exp(\frac{\epsilon u(x,r)}{2 \Delta_{l}u})}
{\Sigma_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u})},
\end{equation*}

where local sensitivity is calculated by:

\begin{equation*}
\Delta_{l}u(x) = 
\max_{\{|x,y'| \leq 1;y'\in \mathcal{X}^n\}}\max_{\{r\in R\}}.
\hlg(\bysinfer(x), r) - \hlg(\bysinfer(y'), r)|
\end{equation*}

\subsubsection{Security Analysis}
We will then prove that exponential mechanism with local sensitivity is non-differentialy private.
\begin{equation*}
\begin{split}
\frac{P[\privinfer(x,u,R) = r]}{P[\privinfer(y,u,R) = r]} 
& = exp\left(
\frac{\epsilon u(x,r)}{2 \Delta_{l}u(x)} - 
\frac{\epsilon u(y,r)}{2 \Delta_{l}u(y)}
\right)  \cdot
\left(\frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}u(y)})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
\right) \\
& = \frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r)}{2 \Delta_{l}u(x)} 
+ \frac{\epsilon u(y,r')}{2 \Delta_{l}u(y)})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r)}{2 \Delta_{l}u(y)} 
+ \frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}.
\end{split}
\end{equation*}

Without loss of generality, we consider the case that $\Delta_{l}u(y) < \Delta_{l}u(x)$, $r = arg(\max\limits_{r' \in R}\{u(x,r')\}) = arg(\min\limits_{r' \in R}\{u(y,r')\})$ and $\Delta_{l}u(y) = u(x,r) - u(y,r)$. We have:
\begin{equation*}
\begin{split}
\frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r)}{2 \Delta_{l}u(x)} 
+ \frac{\epsilon u(y,r')}{2 \Delta_{l}u(y)})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r)}{2 \Delta_{l}u(y)} 
+ \frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
& > \frac
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon (u(x,r) + u(y,r'))}{2 \Delta_{l}u(x)})}
{\sum\limits_{r' \in R}\ exp(\frac{\epsilon (u(y,r) + u(x,r'))}{2 \Delta_{l}u(y)})}\\
& > \frac
{|R|\ exp(\frac{\epsilon (u(x,r) + u(y,r))}{2 \Delta_{l}u(x)})}
{|R|\ exp(\frac{\epsilon (u(y,r) + u(x,r))}{2 \Delta_{l}u(y)})}\\
& = exp(\frac{\epsilon}{2} (\frac{u(x,r) + u(y,r)}{\Delta_{l}u(x)} - \frac{u(x,r) + u(y,r)}{\Delta_{l}u(y)})).
\end{split}
\end{equation*}

From Eq. \ref{equ_utility}, $\{u(x,r') \leq 0|r' \in R\}$ and $\{u(y,r') \leq 0|r' \in R\}$, we can infer that $r = arg(\max\limits_{r \in R}\{u(x,r')\}) = \bysinfer(x)$ and $u(x,r) = 0$.From $\Delta_{l}u(y) = u(x,r) - u(y,r)$, we can also infer that $\Delta_{l}u(y) = - u(y,r)$. Then, the following relationship between $u(x,r)$, $u(y,r)$, $\Delta_{l}u(x)$ and $\Delta_{l}u(y)$:
\begin{equation*}
\begin{split}
- \Delta_{l}u(x) & < \Delta_{l}u(y) \\
\Delta_{l}u(x) - \Delta_{l}u(y) & < 2 \Delta_{l}u(x) \\
- \Delta_{l}u(y) (\Delta_{l}u(y) - \Delta_{l}u(x)) 
& < 2 \Delta_{l}u(x) \Delta_{l}u(y) \\
u(y,r) (\Delta_{l}u(y) - \Delta_{l}u(x)) 
& < 2 \Delta_{l}u(x) \Delta_{l}u(y) \\
\frac{u(x,r) + u(y,r)}{\Delta_{l}u(x)} - \frac{u(x,r) + u(y,r)}{\Delta_{l}u(y)} & > 2.
\end{split}
\end{equation*}

% \begin{equation*}
% \begin{split}
% \frac{\Delta_{l}u(x)}{\Delta_{l}u(y)} & > 0\\
% & > \frac{\Delta_{l}u(x)}{2u(y,r)}\\
% & = \frac{\Delta_{l}u(x) + 0}{2u(y,r)} \\
% & = \frac{\Delta_{l}u(x) + 2 u(x,r)}{2u(y,r)}
% \end{split}
% \end{equation*}
holds.
 
Then we can have:
\begin{equation*}
\begin{split}
& exp(\frac{\epsilon}{2} (\frac{u(x,r) + u(y,r)}{\Delta_{l}u(y)} - \frac{u(x,r) + u(y,r)}{\Delta_{l}u(x)}))\\
& > exp(\frac{\epsilon}{2} * 2) \\
& = exp(\epsilon),
\end{split}
\end{equation*}
i.e.
\begin{equation*}
\begin{split}
\frac{P[\privinfer(x,u,R) = r]}{P[\privinfer(y,u,R) = r]}
& > exp(\epsilon).
\end{split}
\end{equation*}

Since there are cases where exponential mechanism with local sensitivity's privacy loss is greater than $e^{\epsilon}$. we can say it is non-differentially private.
% \begin{equation*}
% \begin{split}
% & \epsilon = 0.1\\
% data size = 2\\
% the prior is Beta(2ï¼Œ2)\\
% data set x = [1,0,]\\
% data set y = [0,0]\\
% -0.313380201461\\
% -0.0\\
% -0.313380201461\\
% 3 3\\
% 0.313380201461\\
% 0.322043464396\\
% 0.355913071207\\
% 0.322043464396\\
% -0.0\\
% -0.313380201461\\
% -0.57735026919\\
% 2 4\\
% 0.375460728684\\
% 0.360050126956\\
% 0.331218326999\\
% 0.308731546045
% \end{split}
% \end{equation*}

% Without loss of generality, we consider the case that $\Delta_{l}u(y) > \Delta_{l}u(x)$ and $\Delta_{l}u(x) = u(x,r) - u(y,r)$. We have:
% \begin{equation*}
% \begin{split}
% exp\left(
% \frac{\epsilon u(x,r)}{2 \Delta_{l}u(x)}
% - \frac{\epsilon u(y,r)}{2 \Delta_{l}u(y)}
% \right)
% & > exp\left(
% \frac{\epsilon u(x,r)}{2 \Delta_{l}u(x)}
% - \frac{\epsilon u(y,r)}{2 \Delta_{l}u(x)}
% \right)\\
% & = exp\left(
% \frac{\epsilon u(x,r) - \epsilon u(y,r)}{2 \Delta_{l}u(x)}
% \right) \\
% & = exp(\frac{\epsilon}{2});
% \end{split}
% \end{equation*}

% \textcolor{red}{For the second part:
% , we have:
% \begin{equation*}
% \begin{split}
% \frac{\epsilon u(y,r')}{2 \Delta_{l}(y)} - \frac{\epsilon u(x,r')}{2 \Delta_{l}(x)} 
% & < \frac{\epsilon u(y,r')}{2 \Delta_{l}(y)} - \frac{\epsilon u(x,r')}{2 \Delta_{l}(y)}\\
% & \leq \frac{\epsilon}{2}
% \end{split}
% \end{equation*}
% I cannot replace $exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}(y)})$ in $\left(\frac
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}u(y)})}
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right)$ with $ > exp(\frac{\epsilon}{2}) \cdot exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}(x)})$.
% So, I cannot find the relationship between the whole part and $exp(\epsilon)$.}

% For the second part:
% \begin{equation*}
% \begin{split}
% \left(\frac
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}u(y)})}
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right)
% & < \left(\frac
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}u(x)})}
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right)\\
% & < \left(\frac
% {exp(\frac{\epsilon}{2})
% \cdot
% \sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right)\\
% & < exp(\frac{\epsilon}{2})
% \end{split}
% \end{equation*}

% For the second part(a tighter bound):
% \begin{equation*}
% \begin{split}
% & \left(\frac
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}u(y)})}
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right) \\
% & = \left(\frac
% {\sum\limits_{r' \in R}\ exp(\frac{\epsilon u(y,r')}{2 \Delta_{l}u(x)})}
% {exp(\frac{\Delta _{l}(y) - \Delta _{l}(x)}{\Delta _{l}(x)  \Delta _{l}(y)})
% \cdot
% \sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right)\\
% & < \left(\frac
% {exp(\frac{\epsilon}{2})
% \cdot
% \sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% {exp(\frac{\Delta _{l}(y) - \Delta _{l}(x)}{\Delta _{l}(x)  \Delta _{l}(y)})
% \cdot
% \sum\limits_{r' \in R}\ exp(\frac{\epsilon u(x,r')}{2 \Delta_{l}u(x)})}
% \right)\\
% & < \left(\frac
% {exp(\frac{\epsilon}{2})}
% {exp(\frac{\Delta _{l}(y) - \Delta _{l}(x)}{\Delta _{l}(x)  \Delta _{l}(y)})}
% \right)\\
% & < exp(\frac{\epsilon}{2} - \frac{\Delta _{l}(y) - \Delta _{l}(x)}{\Delta _{l}(x)  \Delta _{l}(y)})
% \end{split}
% \end{equation*}


\subsection{Exponential Mechanism of Varying Sensitivity}
\label{subsec_emvs}
\subsubsection{Mechanism Setting up}

\subsubsection{Security Analysis}

\subsection{Exponential Mechanism of Smooth Sensitivity}
\label{subsec_emss}
\subsubsection{Mechanism Setting up}

\subsubsection{Security Analysis}


\section{Privacy Fix}

\subsection{Propositions}
Assume we have a prior distribution $beta(1,1)$, an observed data set $x \in \{0,1\}^n$, $n>0$. We use the $x+1$ and $x-1$ to denote:
\begin{small}
\begin{equation*}
\begin{split}
&\mathsf{if\ BayesInfer}(x) = beta(a_1 + 1,b_1 + 1)\\
&\mathsf{then}\mathsf{\ BayesInfer}(x + 1) = beta((a_1 + 1) +1, (b_1 - 1)+1)\\
&\quad \quad \mathsf{\ BayesInfer}(x - 1) = beta((a_1 - 1) +1, (b_1 + 1)+1),\\
\end{split}
\end{equation*}
\end{small}

$x_0$ to denote:
\begin{small}
\begin{equation*}
\begin{split}
&\mathsf{if}\ n\ is\ even\\
&\mathsf{then}\ \bysinfer(x_0) = beta(\frac{n}{2} + 1, \frac{n}{2} + 1)\\
&\mathsf{else}\ \bysinfer(x_0) = \{beta(\frac{n+1}{2} + 1, \frac{n-1}{2} + 1),\\
&\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad beta(\frac{n - 1}{2} + 1, \frac{n + 1}{2} + 1)\}
\end{split}
\end{equation*}
\end{small}

$\betafun(\alpha, \beta)$ is the beta function with two arguments $\alpha$ and $\beta$.

Then, we have the following three statements, and proofs of the statements.
\renewcommand{\labelenumi}{\Roman{enumi}}
\begin{enumerate}
\item $\hlg (\bysinfer(x), \bysinfer(x + 1)) < \hlg (\bysinfer(x + 1), \bysinfer(x + 2))\ \forall x \geq x_0$;

or $\hlg (\bysinfer(x), \bysinfer(x + 1)) > \hlg (\bysinfer(x + 1), \bysinfer(x + 2))\forall x \leq x_0$.

\item $\Delta_{l}u(x) = \hlg (\bysinfer(x),\bysinfer(x + 1)),\forall x \geq x_0$;

$\Delta_{l}u(x) = \hlg (\bysinfer(x),\bysinfer(x - 1)),\forall x \leq x_0$.

\item $\forall x \neq x_0: \Delta_{l}u(x) > \Delta_{l}u(x_0)$.
\end{enumerate}

\subsection{proof}

\subsubsection{Statement I}
We use the MI (Mathematical Induction) method to prove the first statement.

\begin{proof}
Since the Hellinger distance is symmetric, if we prove the $\hlg (\bysinfer(x), \bysinfer(x + 1)) < \hlg (\bysinfer(x + 1), \bysinfer(x + 2))\ \forall x \geq x_0$, the other part when $\forall x \leq x_0$ also holds.

1. if $x = x_0$, $\hlg (\bysinfer(x_0), \bysinfer(x_0 + 1)) < \hlg (\bysinfer(x_0 + 1), \bysinfer(x_0 + 2))$ holds:


% \twocolumn{
\begin{small}
\begin{equation*}
\begin{split}
\hlg(
beta(\frac{n}{2} + 1, \frac{n}{2} + 1), 
beta(\frac{n}{2} + 1 + 1, \frac{n}{2} + 1 - 1))
& <  \hlg(
beta(\frac{n}{2} + 1 + 1, \frac{n}{2} + 1 - 1), 
beta(\frac{n}{2} + 1 + 2, \frac{n}{2} + 1 - 2))\\
\sqrt{1 - \frac{\betafun(
\frac{\frac{n}{2} + 1 + \frac{n}{2} + 1 + 1}{2},
\frac{\frac{n}{2} + 1 + \frac{n}{2} + 1 - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 1, \frac{n}{2} + 1)
\betafun(\frac{n}{2} + 1 + 1, \frac{n}{2} + 1 - 1)
}
}
}
& < \sqrt{1 - \frac{\betafun(
\frac{\frac{n}{2} + 1 + 1 + \frac{n}{2} + 1 + 2}{2}, 
\frac{\frac{n}{2} + 1 - 1 + \frac{n}{2} + 1 - 2}{2}, )}
{\sqrt{
\betafun(\frac{n}{2} + 1 + 1, \frac{n}{2} + 1 - 1)
\betafun(\frac{n}{2} + 1 + 2, \frac{n}{2} + 1 - 2)
}
}
}\\
\sqrt{1 - \frac{\betafun(\frac{n + 3}{2},\frac{n + 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 1, \frac{n}{2} + 1)
\betafun(\frac{n}{2} + 2, \frac{n}{2})
}
}
}
& < \sqrt{1 - \frac{\betafun(\frac{n + 5}{2}, \frac{n - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2, \frac{n}{2})
\betafun(\frac{n}{2} + 3, \frac{n}{2} - 1)
}
}
}\\
\frac{\betafun(\frac{n + 3}{2},\frac{n + 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 1, \frac{n}{2} + 1)
\betafun(\frac{n}{2} + 2, \frac{n}{2})
}
}
& > \frac{\betafun(\frac{n + 5}{2}, \frac{n - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2, \frac{n}{2})
\betafun(\frac{n}{2} + 3, \frac{n}{2} - 1)
}
}\\
\frac{\betafun(\frac{n + 3}{2},\frac{n - 1}{2}) 
\frac{\frac{n - 1}{2}}{\frac{n - 1}{2} + \frac{n + 3}{2}}}
{\sqrt{
\betafun(\frac{n}{2} + 1, \frac{n}{2} - 1) 
\frac{\frac{n}{2} - 1}{\frac{n}{2} - 1 + \frac{n}{2} + 1} 
\frac{\frac{n}{2}}{\frac{n}{2} + \frac{n}{2} + 1}}}
& > \frac{
\betafun(\frac{n + 3}{2}, \frac{n - 1}{2}) 
\frac{\frac{n + 3}{2}}{\frac{n + 3}{2} + \frac{n - 1}{2}} }
{\sqrt{
\betafun(\frac{n}{2} + 1, \frac{n}{2} - 1) 
\frac{\frac{n}{2} + 1}{\frac{n}{2} + 1 + \frac{n}{2} - 1}
\frac{\frac{n}{2} + 2}{\frac{n}{2} + 2 + \frac{n}{2} - 1}}}\\
\frac{\frac{n - 1}{2}}{\sqrt{(\frac{n}{2} - 1)(\frac{n}{2})}}
& > \frac{\frac{n + 3}{2}}{\sqrt{(\frac{n}{2} + 1)(\frac{n}{2} + 2)}}\\
(n - 1) ^ 2 (n + 2)(n + 4)
& > (n + 3) ^ 2 n (n - 2)\\
n & > -1.
\end{split}
\end{equation*}
\end{small}

Since $n > 0$, it always holds.

2. if $x = x_0 + m$ holds, then also $x = x_0 + m + 1$ holds:

i.e $\hlg(beta(\frac{n}{2} + 1 + m, \frac{n}{2} + 1 - m), beta(\frac{n}{2} + 1 + m + 1, \frac{n}{2} + 1 - m - 1)) 
< \hlg(beta(\frac{n}{2} + 1 + m + 1, \frac{n}{2} + 1 - m - 1), beta(\frac{n}{2} + 1 + m + 2, \frac{n}{2} + 1 - m - 2))$
is what we know:

\begin{small}
\begin{equation*}
\begin{split}
\sqrt{
1 - \frac{\betafun(
\frac{\frac{n}{2} + 1 + m + \frac{n}{2} + 1 + m + 1}{2},
\frac{\frac{n}{2} + 1 - m + \frac{n}{2} + 1 - m - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 1 + m, \frac{n}{2} + 1 - m)
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
}
}
}
& < \sqrt{
1 - \frac{\betafun(
\frac{\frac{n}{2} + 1 + m + 1 + \frac{n}{2} + 1 + m + 2}{2},
\frac{\frac{n}{2} + 1 - m - 1 + \frac{n}{2} + 1 - m - 2}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
}
}
}\\
\\
\frac{\betafun(\frac{n + 2m + 3}{2}, \frac{n - 2m + 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 1 + m, \frac{n}{2} + 1 - m)
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
}
}
& > \frac{\betafun(\frac{n + 2m + 5}{2}, \frac{n - 2m - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
}
}
\end{split}
\end{equation*}
\end{small}

Now, we need to proof $\hlg(beta(\frac{n}{2} + 1 + m + 1, \frac{n}{2} + 1 - m - 1), beta(\frac{n}{2} + 1 + m + 2, \frac{n}{2} + 1 - m - 2)) 
< \hlg(beta(\frac{n}{2} + 1 + m + 2, \frac{n}{2} + 1 - m - 2), beta(\frac{n}{2} + 1 + m + 3, \frac{n}{2} + 1 - m - 3))$ by using what we know.


From $x = x_0 + m$ and property of $\betafun(\alpha, \beta)$ function, we know:

\begin{small}
\begin{equation*}
\begin{split}
 \frac{\betafun(\frac{n + 2m + 5}{2}, \frac{n - 2m - 1}{2})
\frac{n - 2m - 1}{n + 2m + 3}}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
\frac{n - 2m}{n + 2m + 2}
}
}
> & \frac{\betafun(\frac{n + 2m + 7}{2}, \frac{n - 2m - 3}{2})
\frac{n - 2m - 3}{n + 2m + 5}}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
\frac{n - 2m - 2}{n + 2m + 6}
}
}\\
\end{split}
\end{equation*}

\begin{equation*}
\begin{split}
\frac{\betafun(\frac{n + 2m + 5}{2}, \frac{n - 2m - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
}
}
> & \frac{\betafun(\frac{n + 2m + 7}{2}, \frac{n - 2m - 3}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
}
}\\
\\
\sqrt{1 - \frac{\betafun(\frac{n + 2m + 5}{2}, \frac{n - 2m - 1}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
}
}}
< & \sqrt{1 - \frac{\betafun(\frac{n + 2m + 7}{2}, \frac{n - 2m - 3}{2})}
{\sqrt{
\betafun(\frac{n}{2} + 2 + m, \frac{n}{2} - m)
\betafun(\frac{n}{2} + 3 + m, \frac{n}{2} - m - 1)
}
}}\\
\\
\hlg(beta(\frac{n}{2} + 2 + m, \frac{n}{2} - m), beta(\frac{n}{2} + 3 + m, \frac{n}{2} - 1 - m))
< & \hlg(beta(\frac{n}{2} + m + 3, \frac{n}{2} - 1 - m), beta(\frac{n}{2} + m + 4, \frac{n}{2} - m - 2))\\
\end{split}
\end{equation*}
\end{small}

i.e. $ x = x_0 + m + 1$ also holds when $x = x_0 + m$ is valid.
\end{proof}


\subsubsection{Statement II}
\begin{proof}

\begin{equation*}
\begin{split}
\because \footnote{the symbol of $\because$ here means because}
\quad 		& \Delta_l u(x) = \max_{\{|x,y'| \leq 1;y'\in \mathcal{X}^n\}}\max_{\{r\in R\}} |\hlg(\bysinfer(x), r) - \hlg(\bysinfer(y'), r)|,\\
\because \quad 		& \hlg(\bysinfer(x), r) - \hlg(\bysinfer(y'), r) \leq \hlg(\bysinfer(x), \bysinfer(y'));\\
\therefore \footnote{the symbol of $\therefore$ here means therefore}
\quad 	& \Delta_l u(x) = \max_{\{|x,y'| \leq 1; y'\in \mathcal{X}^n\}} \hlg(\bysinfer(x), \bysinfer(y')),\\
\therefore \quad 	& \Delta_l u(x) = \max \{\hlg(\bysinfer(x), \bysinfer(x + 1)), \hlg(\bysinfer(x), \bysinfer(x - 1))\};\\
					& According\ to\ Statement\ I:\\
\mathsf{if}	  \quad	& x > x_0 \\
\mathsf{then} \quad	
					& \hlg(\bysinfer(x), \bysinfer(x - 1)) < \hlg(\bysinfer(x), \bysinfer(x + 1));\\
\mathsf{then} \quad	
					& \Delta_l u(x) = \hlg(\bysinfer(x), \bysinfer(x + 1));\\
\mathsf{if}	 \quad	& x < x_0 \\
\mathsf{then} \quad	
					& \hlg(\bysinfer(x), \bysinfer(x - 1))  > \hlg(\bysinfer(x), \bysinfer(x + 1)); \\
\mathsf{then} \quad	
					& \Delta_l u(x) = \hlg(\bysinfer(x), \bysinfer(x - 1));\\
\mathsf{else} \quad	
					& \Delta_l u(x_0) = \hlg(\bysinfer(x_0), \bysinfer(x_0 - 1)) = \hlg(\bysinfer(x_0), \bysinfer(x_0 + 1)). \\
\end{split}
\end{equation*}

From above, we can conclude the Statement II.

\end{proof}

\subsubsection{Statement III}
\begin{proof}
From Statement I and Statement II, we can conclude that:
\begin{equation*}
\begin{split}
\mathsf{when} \quad	& x > x_0 \\
					& \hlg(\bysinfer(x), \bysinfer(x + 1) > \hlg(\bysinfer(x_0), \bysinfer(x_0 + 1); \\
					& i.e.\ \Delta_l u(x) > \Delta_l u(x_0)\\
\mathsf{when} \quad	& x < x_0 \\
					& \hlg(\bysinfer(x), \bysinfer(x - 1)  > \hlg(\bysinfer(x_0), \bysinfer(x_0 - 1); \\
					& i.e.\ \Delta_l u(x) > \Delta_l u(x_0).\\
\end{split}
\end{equation*}

i.e $\forall \ x \neq x_0, \Delta_l u(x) > \Delta_l u(x_0)$.

\end{proof}

\section{Smooth sensitivity}
\label{sec_smoo}

\subsection{Dilation Property of Laplace Noise}
\label{sec_Dila}
\begin{lem}
For 1-dimensional Laplace distribution: $h(z) = \frac{1}{2} e^{-|z|}$, $\alpha = \frac{\epsilon}{2}$, $\beta = \frac{\epsilon}{2 \rho_{\delta/3}(|z|)}$ or $ \frac{\epsilon}{2 ln(2/\delta)}$ and $|\lambda| \leq \beta$, the dilation property holds for any $z$ sampled from $h$:
\begin{equation*}
Pr[z \in S] \leq e^{\frac{\epsilon}{2}} Pr[z \in e^{\lambda} S] + \frac{\delta}{2}
\end{equation*}
\end{lem}

\begin{proof}

\begin{itemize}

	From the integral substitution property, we have:

	\begin{equation*}
	\begin{split}
	\frac{Pr[z \in e^{\lambda} S]}{Pr[z \in S]} 
		= &\frac
		{\int_{e^{\lambda} S}{} \frac{1}{2}e^{-|z|} dz}
		{\int_{S}{} \frac{1}{2}e^{-|z|} dz} \\
		= &\frac
		{\int_{S}{} \frac{1}{2}e^{-|e^{\lambda}z|} e^{\lambda} dz}
		{\int_{S}{} \frac{1}{2}e^{-|z|}dz} \\
		= & \frac{e^{-|e^{\lambda}z|} e^{\lambda}}{e^{-|z|}} \\
		= & \frac{e^{\lambda} h(e^{\lambda} z)}{h(z)}\\
	\end{split}
	\end{equation*}

	Then, we proof the dilation property in cases of $\lambda > 0$ and $\lambda < 0$ separately:

	\item \textbf{case 1: $\lambda > 0$}

	\begin{equation*}
	\begin{split}
	\because\ 		& 	h(e^{\lambda} z) =  \frac{1}{2} e^{-|e^{\lambda} z|} < \frac{1}{2} e^{-|z|} = h(z)\\
	\therefore\		& 	\frac{Pr[z \in e^{\lambda} S]}{Pr[z \in S]} 
					% 	= \frac
					% 	{\int_{e^{\lambda} S}{} \frac{1}{2}e^{-|z|} dz}
					% 	{\int_{S}{} \frac{1}{2}e^{-|z|} dz} 
					% 	= \frac
					% 	{\int_{S}{} \frac{1}{2}e^{-|e^{\lambda}z|} e^{\lambda} dz}
					% 	{\int_{S}{} \frac{1}{2}e^{-|z|}dz} \\
					% &	= \frac{e^{-|e^{\lambda}z|} e^{\lambda}}{e^{-|z|}}
						= \frac{e^{\lambda} h(e^{\lambda} z)}{h(z)}
						\leq e^{\lambda}\\
	\therefore\		&	ln(\frac{e^{\lambda} h(e^{\lambda} z)}{h(z)})
						\leq \lambda \\
	\because\		&	\lambda \leq \beta = \frac{\epsilon}{2 ln(3 / \delta)}, \delta < 1 \\
	\therefore\		&	\lambda \leq \frac{\epsilon}{2} \\
	\therefore\		&	\frac{Pr[z \in e^{\lambda} S]}{Pr[z \in S]} \leq \frac{\epsilon}{2} \\
	\end{split}
	\end{equation*}

	\item \textbf{case 2: $\lambda < 0$}
	% \begin{equation*}
	% \begin{split}
	% \because\	& \frac{h(e^{\lambda} z)}{h(z)} = exp(|z|(1 - e^{\lambda})) \leq |\lambda|\\
	% \therefore\	& ln(\frac{e^{\lambda} h(e^{\lambda} z)}{h(z)}) \leq |z||\lambda|\\
	% \end{split}
	% \end{equation*}

	% We consider an event $G = \{z |\ |z|\leq log(\frac{1}{\delta}) \}$. Under this event, we have:

	% \begin{equation*}
	% |z||\lambda| \leq log(\frac{1}{\delta})|\lambda| \leq log(\frac{1}{\delta})\frac{\epsilon}{2 log(\frac{3}{\delta})} \leq \frac{\epsilon}{2}.
	% \end{equation*}

	% Also, from the Laplace distribution property we have:

	% \begin{equation*}
	% Pr[G] \geq 1 - \delta ;
	% \end{equation*}

	% \begin{equation*}
	% Pr[\overline{G}] \leq \delta .
	% \end{equation*}

	% We start from the thing we want to proof:

	% \begin{equation*}
	% Pr[z \in S] \leq e^{\frac{\epsilon}{2}} Pr[z \in e^{\lambda} S] + \frac{\delta}{2};
	% \end{equation*}

	% \begin{equation*}
	% \begin{split}
	% \underset{z \thicksim Lap(1)}{Pr}[z \in S] \leq & Pr[z \in S \cap G] + Pr[z \in \overline{G}]\\
	% \leq 	& Pr[z \in S \cap G] + \delta\\
	% \leq 	& e^{|z||\lambda|} \underset{z \thicksim Lap(e^{\lambda})}{Pr}[z \in S \cap G] + \delta \\
	% \leq	& e^{|z||\lambda|} \underset{z \thicksim Lap(e^{\lambda})}{Pr}[z \in S] + \delta\\
	% \leq	& e^{\frac{\epsilon}{2}} \underset{z \thicksim Lap(e^{\lambda})}{Pr}[z \in S] + \delta\\
	% =		& e^{\frac{\epsilon}{2}} \underset{z \thicksim Lap(1)}{Pr}[z \in e^{\lambda} S] + \delta\\
	% \end{split}
	% \end{equation*}
	From integral property, we firstly have:

	\begin{equation*}
	\frac{Pr[z\in e^{\lambda} S]}{Pr[z\in S]} 
	= \frac{e^{-|e^{\lambda}z|} e^{\lambda}}{e^{-|z|}} 
	= \frac{h(e^{\lambda} z) e^{\lambda}}{h(z)} 
	= e^{\lambda}e^{|z|(1 - e^{\lambda})}
	\end{equation*}



	\begin{equation*}
	\begin{split}
	\because\	& 1 - e^{\lambda} \leq |\lambda| \\
	\therefore\	& \ln (\frac{h(e^{\lambda} z) e^{\lambda}}{h(z)} )
	\leq \lambda + |z||\lambda|\\
	\because\	& \lambda < 0\\
	\therefore\	& \ln (\frac{h(e^{\lambda} z) e^{\lambda}}{h(z)} )
	\leq |z||\lambda|\\
	\end{split}
	\end{equation*}

	By setting $h'(z) = e^{\lambda} h(e^{\lambda} z)$, we can get:

	\begin{equation*}
	\begin{split}
	&\ln(\frac{h'(z)}{h(z)}) \leq |z||\lambda|\\
	\Rightarrow & h'(z)\leq  e^{|z||\lambda|}h(z)
	\end{split}
	\end{equation*}

	By exchanging the notation of $h'$ and $h$, we have:

	\begin{equation*}
	h(z) \leq e^{|z||\lambda|}h'(z)
	\end{equation*}

	i.e.

	\begin{equation*}
	\underset{z \thicksim h}{Pr}[z \in S] 
	\leq  e^{|z||\lambda|}\underset{z \thicksim h'}{Pr}[z \in S]
	= e^{|z||\lambda|}\underset{z \thicksim h}{Pr}[z \in e^{\lambda} S]
	\end{equation*}

	We consider an event $G = \{z |\ |z|\leq log(\frac{2}{\delta}) \}$. Under this event, we have:

	\begin{equation*}
	\begin{split}
	|z||\lambda| 	& \leq log(\frac{2}{\delta})|\lambda|\\
					& \leq log(\frac{2}{\delta}) \beta\\
					&\leq log(\frac{2}{\delta})\frac{\epsilon}{2 log(\frac{3}{\delta})} \\
					&\leq \frac{\epsilon}{2}.
	\end{split}
	\end{equation*}

	Then:

	\begin{equation*}
	\begin{split}
	\underset{z \thicksim h}{Pr}[z \in S \cap G] 
	& \leq  e^{|z||\lambda|}\underset{z \thicksim h'}{Pr}[z \in S\cap G]\\
	& \leq e^{\frac{\epsilon}{2}} \underset{z \thicksim h'}{Pr}[z \in S \cap G]\\
	\end{split}
	\end{equation*}	


	We also have:

	\begin{equation*}
	Pr[\overline{G}] = Pr[|z| > log(\frac{2}{\delta})] = exp(-log(\frac{2}{\delta})) = \frac{\delta}{2}
	\end{equation*}

	Then, we can get

	\begin{equation*}
	\begin{split}
	\underset{z \thicksim h}{Pr}[z \in S] 
	& \leq \underset{z \thicksim h}{Pr}[z \in S\cap G] + \underset{z \thicksim h}{Pr}[z \in \overline{G}]\\
	& \leq e^{\frac{\epsilon}{2}} \underset{z \thicksim h'}{Pr}[z \in S \cap G] + \frac{\delta}{2}\\ 
	& \leq e^{\frac{\epsilon}{2}} \underset{z \thicksim h'}{Pr}[z \in S] + \frac{\delta}{2}\\ 
	& = e^{\frac{\epsilon}{2}} \underset{z \thicksim h}{Pr}[z \in e^{\lambda} S] + \frac{\delta}{2}\\ 
	\end{split}
	\end{equation*}	

	i.e. the dilation property.

\end{itemize}

\end{proof}

\subsection{Sliding Property of Exponential Mechanism}
\begin{lem}
for any exponential mechanism $\expomech$, $\lambda = f(\epsilon, \delta)$, $\epsilon$ and $|\delta| < 1$, the sliding property holds:

\begin{equation*}
\underset{z \thicksim \expomech}{Pr}[u(r,x) = \hat{s}]
\leq
e^{\frac{\epsilon}{2}} \underset{z \thicksim \expomech}{Pr}[u(r,x) = (\Delta + \hat{s})] + \frac{\delta}{2},
\end{equation*}
where the sensitivity in mechanism is smooth sensitivity $S(x)$, calculated by:
\begin{equation*}
S_{\beta}(x) = \max(\Delta_{l}u(x), \max_{y \neq x; y \in D^{n}}(\Delta_{l}u(y)\cdot e^{-\beta d(x,y)})),
\end{equation*}
where $\beta = \beta(\epsilon, \delta)$.

\end{lem}

\begin{proof}
We denote the normalizer of the probability mass in $\expomech$: $\sum_{r' \in \mathcal{R}}exp(\frac{\epsilon u(r',x)}{2 S(x)})$ as $NL_x$:
\begin{equation*}
\begin{split}
LHS 
  = \underset{z \thicksim \expomech}{Pr}[u(r,x) = \hat{s}]
& = \frac{exp(\frac{\epsilon \hat{s}}{2 S(x)})}{NL_x}\\
& = \frac{exp(\frac{\epsilon (\hat{s} + \Delta - \Delta)}{2 S(x)})}{NL_x}\\
& = \frac{exp(\frac{\epsilon (\hat{s} + \Delta)}{2 S(x)} + \frac{- \epsilon \Delta}{2 S(x)})}{NL_x}\\
& = \frac{exp(\frac{\epsilon (\hat{s} + \Delta)}{2 S(x)})}{NL_x} \cdot e^{\frac{- \epsilon \Delta}{2 S(x)})}.\\
\end{split}
\end{equation*}

By bounding the $\Delta \geq -S(x)$, we can get:

\begin{equation*}
\begin{split}
\frac{exp(\frac{\epsilon (\hat{s} + \Delta)}{2 S(x)})}{NL_x} \cdot e^{\frac{- \epsilon \Delta}{2 S(x)}}
& \leq \frac{exp(\frac{\epsilon (\hat{s} + \Delta)}{2 S(x)})}{NL_x} \cdot e^{\frac{\epsilon}{2}}\\
&  =  e^{\frac{\epsilon}{2}} \underset{z \thicksim \expomech}{Pr}[u(r,x) = (\Delta + \hat{s})] \leq RHS\\
\end{split}
\end{equation*}

\end{proof}

\subsection{Dilation Property of Exponential Mechanism}
\begin{lem}
for any exponential mechanism $\expomech$, $\lambda = f(\epsilon, \delta)$, $\epsilon$ and $|\delta| < 1$, the dilation property holds:

\begin{equation*}
\underset{r \thicksim \expomech}{Pr}[u(r) = z]
\leq
e^{\frac{\epsilon}{2}} \underset{r \thicksim \expomech}{Pr}[u(r) = e^{\lambda} z] + \frac{\delta}{2},
\end{equation*}
where the sensitivity in mechanism is still smooth sensitivity as above.
\end{lem}

\begin{proof}

% \begin{equation*}
% \begin{split}
% \frac{exp(\frac{\epsilon \hat{s}}{2 S(x)})}{NL_x}
% &  \leq e^{\frac{\epsilon}{2}} \cdot \frac{exp(\frac{\epsilon (\hat{s} \cdot e^{\lambda})}{2 S(x)})}{NL_x}\\
% exp(\frac{\epsilon \hat{s}}{2 S(x)})
% & \leq e^{\frac{\epsilon}{2}} \cdot exp(\frac{\epsilon (\hat{s} \cdot e^{\lambda})}{2 S(x)}) \\
% \frac{\epsilon \hat{s}}{2 S(x)}
% & \leq \frac{\epsilon}{2} + \frac{\epsilon \hat{s} \cdot  e^{\lambda}}{2 S(x)}\\
% \hat{s} & \leq S(x) + \hat{s} \cdot e^{\lambda}\\
% (1 - e^{\lambda}) \cdot \hat{s} & \leq S(x)
% \end{split}
% \end{equation*}

The sensitivity is always greater than 0, and we are using $-\hlg(\bysinfer(x),r)$ for utility function, i.e., $u(r) \leq 0$, we need to consider two cases that $\lambda < 0$, and $\lambda > 0$:

We set the $h(z) = Pr[u(\expomech) = z] = \frac{exp(\frac{\epsilon z}{2 S(x)})}{NL_x}$.

We first consider $\lambda < 0$. In this case, $1 < e ^ {\lambda}$, so the ratio $\frac{h(z)}{h(e^{\lambda}z)} = \frac{exp(\frac{\epsilon z}{2 S(x)})}{exp(\frac{\epsilon (z \cdot e^{\lambda})}{2 S(x)})}$ is at most $\frac{\epsilon}{2}$.

Next, we proof the dilation property for $\lambda > 0$, The ratio of $\frac{h(z)}{h(e^{\lambda}z)}$ is $\exp(\frac{\epsilon}{2} \cdot \frac{u(\expomech) (1 - e^{\lambda})}{S(x)})$. Consider the event $G = \{ \expomech : u(\expomech) \leq \frac{S(x)}{(1 - e^{\lambda})}\}$. Under this event, the log-ratio above is at most $\frac{\epsilon}{2}$. The probability of $G$ under density $h(z)$ is $1 - \frac{\delta}{2}$. Thus, the probability of a given event $z$ is at most $Pr[z \cap G] + Pr[\overline{G}] \leq e^{\frac{\epsilon}{2}} Pr[e^{\lambda}z \cap G] + \frac{\delta}{2} \leq e^{\frac{\epsilon}{2}} Pr[e^{\lambda}z] + \frac{\delta}{2}$. The $\beta$ is set as 

\begin{itemize}

	\item $\lambda < 0$
	% \begin{itemize}
		% \item $u(r) > 0$

		% % This need to be discuss further.
		% % We can have:
		% % \begin{equation*}
		% % \lambda\geq \ln (1 - \frac{S(x)}{\hat{s}}) 
		% % \end{equation*}
		% % Since $\lambda > 0$ is the pre-condition, it can be inferred that the property cannot hold under this case.
		% \item $u(r) \leq 0$

		The left hand side will always be smaller than 0 and the right hand side greater than 0. This will always holds, i.e.
		\begin{equation*}
		\end{equation*}
	\item $\lambda > 0$
	% \begin{itemize}
	% 	% \item $u(r) > 0$

	% 	% The left hand side will always be smaller than 0 and the right hand side greater than 0. This will always holds.

	% 	% \item $u(r) < 0$
	% 	% This need to be discuss further.
	% 	% We can have:
	% 	% \begin{equation*}
	% 	% \lambda\leq \ln (1 - \frac{S(x)}{\hat{s}}) 
	% 	% \end{equation*}
	% \end{itemize}
	% \end{itemize}
% In conclusion, the dilation property holds under these conditions that: $\lambda u(x,r) > 0$ or $\lambda > 0, u(x,r) < 0, \lambda \leq \ln (1 - \frac{S(x)}{\hat{s}})$.


% In our case, we are using $-\hlg(\bysinfer(x),r)$ for utility function, so we only need to consider the case $u(r) \leq 0$.

Because $\hat{s} = u(r)$ where $r \thicksim \expomech$, we can substitute $\hat{s}$ with $u(\expomech)$. Then, what we need to proof under the case $\lambda > 0$ is:
\begin{equation*}
u(\expomech) \leq \frac{S(x)}{(1 - e ^ {\lambda})}
\end{equation*}
By applying the accuracy property of exponential mechanism, we bound the probability that the equation holds with probability:
\begin{equation*}
\begin{split}
Pr[u(\expomech) \leq \frac{S(x)}{(1 - e ^ {\lambda})}] 
& \leq \frac{|\mathcal{R}|exp(\frac{\epsilon S(x)}{(1 - e ^ {\lambda})}/2 S(x))}{|\mathcal{R}_{OPT}| exp(\epsilon OPT_{u(x)}/2 S(x))}\\
\end{split}
\end{equation*}

In our Bayesian Inference mechanism, the size of the candidate set $\mathcal{R}$ is equal to the size of observed data set plus 1, i.e., $n + 1$, and $OPT_{u(x)} = 0$, then we have:
\begin{equation*}
\begin{split}
Pr[u(\expomech) \leq \frac{S(x)}{(1 - e ^ {\lambda})}] 
& = (n + 1)exp(\frac{\epsilon S(x)}{(1 - e ^ {\lambda})}/2 S(x))\\
& = (n + 1)exp(\frac{\epsilon}{2 (1 - e ^ {\lambda})})\\
\end{split}
\end{equation*}

When we set $\lambda \leq \ln(1 - \frac{\epsilon}{2 \ln (\frac{\delta}{2 (n + 1)})})$, it is easily to derive that $Pr[u(\expomech) \leq \frac{S(x)}{(1 - e ^ {\lambda})}] \leq \frac{\delta}{2}$.

\end{itemize}
% So, we only need to proof it in two cases where $\lambda > 0, u(x,r) < 0$ and $\lambda < 0, u(x,r) > 0$.

% We take the absolute value of utility function, then there is only one case we need to discuss: $(1 - e^{\lambda}) |\hat{s}| \leq S(x)$, $\lambda < 0$.

\end{proof}

\section{Experimental Evaluations}
We got some results from these mechanisms.



\end{document}

