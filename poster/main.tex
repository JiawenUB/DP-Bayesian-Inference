%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Dreuw & Deselaer's Poster
% LaTeX Template
% Version 1.0 (11/04/13)
%
% Created by:
% Philippe Dreuw and Thomas Deselaers
% http://www-i6.informatik.rwth-aachen.de/~dreuw/latexbeamerposter.php
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[final,hyperref={pdfpagelabels=false}]{beamer}

%\setbeamercolor{block title}{fg=black,bg=orange!70} % Change the block title color
\input{macros}

\usepackage[orientation=landscape,size=custom,width=101.6,height=76.2,scale=1.4]{beamerposter}
%\usepackage[orientation=portrait,size=a0,scale=1.4]{beamerposter} % Use the beamerposter package for laying out the poster with a portrait orientation and an a0 paper size
\usepackage{proof}
%\usetheme{Icy}
\usetheme{I6pd2} % Use the I6pd2 theme supplied with this template

\setbeamercolor{background canvas}{bg=white!20}

\usepackage[english]{babel} % English language/hyphenation

\usepackage{amsmath,amsthm,amssymb,latexsym} % For including math equations, theorems, symbols, etc

%\usepackage{times}\usefonttheme{professionalfonts}  % Uncomment to use Times as the main font
%\usefonttheme[onlymath]{serif} % Uncomment to use a Serif font within math environments

\boldmath % Use bold for everything within the math environment

\usepackage{booktabs} % Top and bottom rules for tables

\graphicspath{{figures/}} % Location of the graphics files

\usecaptiontemplate{\small\structure{\insertcaptionname~\insertcaptionnumber: }\insertcaption} % A fix for figure numbering

\usepackage{stmaryrd}

%MACROS
\newcommand{\interp}[2]{\llbracket {#2} \rrbracket_{#1}}
\newcommand{\stmod}[1]{\mathfrak{M}[{#1}]}


%----------------------------------------------------------------------------------------
%	TITLE SECTION 
%----------------------------------------------------------------------------------------

\title{\LARGE Tailoring Differentially Private Bayesian Inference to Distance Between Distributions} % Poster title

\author{Mark Bun$^\dag$,
%Imdea Software\\[-3mm]
%\texttt{gjbarthe@gmail.com} \\
%\And 
Gian Pietro Farina$^{*}$,
%University of Dundee\\[-3mm] 
%\texttt{g.p.farina@dundee.ac.uk} \\
%\And
Marco Gaboardi$^{*}$,
%University of Dundee\\[-3mm] 
%\texttt{m.gaboardi@dundee.ac.uk} \\
%\And
Jiawen Liu$^{*}$
%Imdea Software
%\texttt{pierre-yves@strub.nu} \\
}


\institute{$^\dag$Princeton University, $^{*}$University at Buffalo, SUNY} % Institution(s)

%----------------------------------------------------------------------------------------
%	FOOTER TEXT
%----------------------------------------------------------------------------------------

\newcommand{\leftfoot}{Tailoring Differentially Private Bayesian Inference to Distance Between Distributions} % Left footer text

\newcommand{\rightfoot}{mbun@cs.princeton.edu, gaboardi@buffalo.edu} % Right footer text

%----------------------------------------------------------------------------------------

\begin{document}

\addtobeamertemplate{block end}{}{\vspace*{1ex}} % White space under blocks
\begin{frame}[t] % The whole poster is enclosed in one beamer frame

\begin{columns}[t] % The whole poster consists of two major columns, each of which can be subdivided further with another \begin{columns} block - the [t] argument aligns each column's content to the top

\begin{column}{.015\textwidth}\end{column} % Empty spacer column

\begin{column}{.485\textwidth} % The first column

%----------------------------------------------------------------------------------------
%	OBJECTIVES
%----------------------------------------------------------------------------------------

\begin{block}{Objectives}
% \begin{columns} % Subdivide the first main column
% \begin{column}{.69\textwidth}
\begin{enumerate}
\item Designing a differentially private Bayesian inference mechanism.
\item Measuring accuracy with a metric over distributions (Hellinger distance ($\hellinger$), $f$-divergence, etc.).
% \item Calibrating the noise w.r.t sensitivity of the (Hellinger distance).
% \item Applying smooth sensitivity in mechanism to achieve better accuracy.
%         (Fig. \ref{fig_sensitivity} shows that local sensitivity of Hellinger distance is very steep and much higher in the edges but very smooth in central part).
\end{enumerate}
% \end{column}
% \begin{column}{.28\textwidth}
% \begin{figure}[ht]
% \centering
% \includegraphics[width=0.85\textwidth]{poster_0.eps}
% say something about beta...
% \caption{\footnotesize{Local sensitivity of Hellinger}}
% \label{fig_sensitivity}
% \end{figure}
% \vspace{.1cm}
% \end{column}
% \end{columns}

% \noindent Design a mechanism that achieve differential privacy by scaling to a metric between distribution.
% \begin{enumerate}
% \item A differentially private bayesian mechanism,
% \item Calibrating mechanism noise by the same probabilistic distance we want to measure accuracy with.
% \item Applying smooth sensitivity in mechanism to achieve better accuracy.
% \end{enumerate}

\end{block}

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------
            
\begin{block}{Bayesian inference ($\bysinfer$): Example: Beta-Binomial model}
% The first subdivided column within the first main column
% \begin{columns} % Subdivide the first main column
% \begin{column}{.54\textwidth} % The first subdivided column within the first main column
%The prior $\betad(\alpha, \beta)$, with hyperparameters $\alpha,\beta\in\mathbb{R}^{+}$ is conjugate to the likelihood function.
\begin{itemize}
  \item[-] Prior on $\theta: \betad(\alpha, \beta), \alpha,\beta\in\mathbb{R}^{+}$, observed data set $\dataobs= (x_1,\dots x_n)\in\{0,1\}^{n}, n\in\mathbb{N}$.

  \item[-] Likelihood function: $\mathbb{L}_{\dataobs | \theta}= \theta^{\Delta \alpha}(1-\theta)^{n - \Delta \alpha}$, where $\Delta \alpha = \displaystyle\sum_{i=1}^{n}x_i$;

  \item[-] Posterior distribution over theta: $\mathbb{P}_{\theta|\dataobs}=\betad(\alpha + \Delta \alpha,\beta + n - \Delta \alpha)$.
\end{itemize}
\end{block}
% and with p.d.f:

% \[
%   \Pr(\theta)\equiv \frac{\theta^{\alpha} (1- \theta)^{\beta}}{\betaf(\alpha,\beta)}
% \]
% where $\betaf(\cdot,\cdot)$ is the beta function.
%----------------------------------------------------------------------------------------
%	MATERIALS
%----------------------------------------------------------------------------------------

\begin{block}{Differentially Private Bayesian Inference and Motivations}
Releasing a differentially private posterior $\betad (\tilde\alpha,\tilde\beta)=(\alpha +  \widetilde{\Delta \alpha},\beta + n - \widetilde{\Delta \alpha})$.
\begin{columns} % Subdivide the first main column
\begin{column}{.69\textwidth}
\begin{enumerate}
  \item  Baseline approach is Laplace mechanism (LapMech) with sensitivity proportional to $\ell_1$ norm. But this sensitivity grows linear with the dimension, also we measure results by a different metric. Motivated by this, we calibrate the noise w.r.t sensitivity of the accuracy metric ($\hellinger$). %(v.s. the $\ell_1$ norm in baseline approach).} \todo{} % \todo{give formula of hellinger Distance, give the Dirichlet distribution, no need to formal expression, Laplace with mean and scale in 2 dimension.}
  \item Maximum sensitivity of $\hellinger$ over $\betad$ distributions achieves at edges as in Fig. \ref{fig_sensitivity}. But it's very low when move away from edge. Motivated by this, we apply smooth sensitivity in mechanism to improve accuracy.
  %{sensitivity is maximize when plot of hellinger distance of alpha and beta variance between adjacent data bases, of varying }
\end{enumerate}
\end{column}
\begin{column}{.28\textwidth}
\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{poster_0.eps}
\caption{\footnotesize{Sensitivities of $\hellinger$ over $\betad$}}
\label{fig_sensitivity}
\end{figure}
% \vspace{.1cm}
\end{column}
\end{columns}

\end{block}

%----------------------------------------------------------------------------------------
% OUR APPROACH
%----------------------------------------------------------------------------------------


\begin{block}{Smoothed Hellinger Distance Based Exponential Mechanism}

We define the mechanism $\hexpmech$ which produces an element $r$ in $\betaset$ with probaiblity:
\[
\underset{z \thicksim \hexpmech}{\Pr}[z=r] = 
\frac 
{\exp \Big(\frac{-\epsilon\cdot\hellinger(\bysinfer(\dataobs),r)}{2\cdot S(\dataobs)}\Big)}
{\sum_{r\in\betaset} \exp \Big(\frac{-\epsilon\cdot\hellinger(\bysinfer(\dataobs),r)}{2\cdot S(\dataobs)}\Big)}
\]

given in input an observations $\dataobs$, parameters $\epsilon>0$ and $\delta>0$, where:

\begin{itemize}
  \item[-] $\betaset$, the candidates set defined as $\{\betad(\alpha',\beta')\mid \alpha'=\alpha+\Delta\alpha, \beta'=\beta+n-\Delta\alpha\}$, given the prior distribution $\bprior=\betad(\alpha, \beta)$ and observed data set size $n$.

  \item[-] $-\hellinger(\bysinfer(\dataobs),r)$ denotes the scoring function based on the Hellinger distance.

  \item[-] $S(\dataobs)$, the smooth sensitivity\cite{nissim2007smooth}:
  $
  S(\dataobs)=\max_{\dataobs' \in \{0,1\}^{n}}\big\{ LS(\dataobs') \cdot e^{-\gamma\cdot d(\dataobs,\dataobs')}\big\}
  $,
  where:
  \begin{itemize}
   \item $d$: Hamming distance between two data sets,

   \item $LS(\dataobs')$, local sensitivity at $\dataobs'$:
   $
   LS(\dataobs)=\max\limits_{\dataobs' \in \datauni^n:\adj{\dataobs}{\dataobs'}, r\in \mathcal{R}}\lvert \hellinger(\bysinfer(\dataobs), r) - \hellinger(\bysinfer(\dataobs'), r)\rvert
   $,

   \item $\gamma =   \ln(1 - \frac{\epsilon}{2 \ln (\frac{\delta}{2 (n + 1)})})$ to ensure the $(\epsilon,\delta)$-differentially private.
 \end{itemize}
\end{itemize}


\end{block}


\end{column} % End of the first column

\begin{column}{.01\textwidth}\end{column} % Empty spacer column
 
\begin{column}{.485\textwidth} % The second column






\begin{block}{Preliminary Experimental Results}
% Two groups of experimental results both with unit prior $\betad(1,1), \betad(1,1,1)$ and $\betad(1,1,1,1)$, balanced datasets and parameters $\epsilon = 1.0$ and $\delta = 10^{-8}$.
Experiments are on three mechanisms and plotted as follows:
\begin{itemize}
  \item[-] Green: Baseline approach. (noises being postprocessed to floor value) %adds noise scaled to sensitivity proportional to dimensionality,
  \item[-] Red: LapMech with sensitivity $1$ in 2 dimensions and $2$ in higher dimensions, since it's equivalent to histogram problem 
  (posteriors of adjacent data sets differ only in two dimensions).
  \item[-] Blue: $\hexpmech$.
\end{itemize}
  Fig. \ref{fig_sampling} and Fig. \ref{subfig_prior} give us the average and 4-quantile of Hellinger distance between the sampled results and true posterior, by sampling for $10k$ times under each data size or prior configuration.

\begin{figure}[H]
\begin{center}
\centering
  \subfigure[\footnotesize{2 dimensions, data size $\in [100,500]$}]{
    \includegraphics[width=0.333\textwidth]{poster_1.eps}
    \label{subfig_sampling_2d}
  }
  \subfigure[\footnotesize{3 dimensions, data size $\in [100,500]$} ]{
    \includegraphics[width=0.302\textwidth]{poster_2.eps}
  \label{subfig_sampling_3d}
  } 
  \subfigure[\footnotesize{4 dimensions, data size $\in [100,600]$}]{
    \includegraphics[width=0.295\textwidth]{poster_3.eps}
    \label{subfig_sampling_4d}
  }
  \caption{Average accuracy by increasing data set size}
\label{fig_sampling}
\end{center}
\end{figure}

Fig. \ref{subfig_concrete_prob_2d} and \ref{subfig_concrete_prob_3d} give us the discrete probabilities. On the x-axis: the distance of a potential output r from the true answer and on y-axis the probability of r being output by the mechanisms.
\begin{figure}[H]
\begin{center}
\centering
   \subfigure[2 dimensions with data size $100$]{
    \includegraphics[width=0.31\textwidth]{poster_4.eps}
  \label{subfig_prior}
  }
  \subfigure[2 dimensions with data size $600$]{
    \includegraphics[width=0.311\textwidth]{poster_5.eps}
  \label{subfig_concrete_prob_2d}
  }
  \subfigure[3 dimensions with data size $600$]{
    \includegraphics[width=0.311\textwidth]{poster_6.eps}
  \label{subfig_concrete_prob_3d}
  } 
\caption{4-quantile and discrete probability plots}
\label{fig_concrete_prob}
\end{center}
\end{figure}
\scriptsize{Experiments above are with unit prior $\betad(1,1), \betad(1,1,1)$ and $\betad(1,1,1,1)$ (except Fig. \ref{subfig_prior}) , balanced datasets, $\epsilon = 1.0$ and $\delta = 10^{-8}$.}
\end{block}


%----------------------------------------------------------------------------------------
% CONCLUSION
%----------------------------------------------------------------------------------------


\begin{block}{Conclusion}

\begin{itemize}
  \item[-] The smoothed Hellinger distance based exponential mechanism outperforms asymptotically the baseline 
  approach when the latter uses a sensitivity proportional to dimensionality.
  \item[-] Under the same data set size, $\hexpmech$ can outperform LapMech by increasing the prior.
  % \begin{enumerate}
  %   \item  The accuracy that we are going to explore next, and in a more principled and formal way.
    
  %   \item  Experiments have shown that the actual privacy loss
  % in the experiments can be smaller than $\epsilon$. This means that we
  % could improve accuracy, by adding less noise but still achieve
  % $(\epsilon, \delta)$-dp.

  %   \item The choice of the Hellinger distance might seem quite ad-hoc. Hence, it is worth exploring other distances over distributions. An interesting class of probability metrics is the family of $f$-divergences \cite{CIT-004}.

  %   \item Other application of our scheme are going to be explored.
  % \end{enumerate}
\end{itemize}
%\vspace{8mm}
%\vspace{8mm}
%where we require $t$ and $u$ to have distinct sets of free variables.
\end{block}


%----------------------------------------------------------------------------------------
%	RESULTS
%----------------------------------------------------------------------------------------




%------------------------------------------------

% \begin{block}{Results: Figure}

% \begin{figure}
% \includegraphics[width=0.8\linewidth]{placeholder.jpg}
% \caption{Figure caption}
% \end{figure}

% \end{block}



%----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------

\begin{block}{References}
        
%\nocite{*} % Insert publications even if they are not cited in the poster
\small{\bibliographystyle{unsrt}
\bibliography{bayesian}}

\end{block}

%----------------------------------------------------------------------------------------
%	ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

% \begin{block}{Acknowledgments}

% \begin{itemize}
% \item Nam mollis tristique neque eu luctus. Suspendisse rutrum congue nisi sed convallis. Aenean id neque dolor. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.
% \end{itemize}

% \end{block}

%----------------------------------------------------------------------------------------
%	CONTACT INFORMATION
%----------------------------------------------------------------------------------------

\setbeamercolor{block title}{fg=black,bg=orange!70} % Change the block title color

% \begin{block}{Contact Information}

% \begin{itemize}
% \item \textbf{Marco Gaboardi}
% \item Web: \href{http://staff.computing.dundee.ac.uk/marcogaboardi/}{http://staff.computing.dundee.ac.uk/marcogaboardi/}
% \item Email: \href{mailto:m.gaboardi@dundee.ac.uk}{m.gaboardi@dundee.ac.uk}
% %\item Phone: +1 617-384-9606
% \end{itemize}

% \end{block}

%----------------------------------------------------------------------------------------

\end{column} % End of the second column

\begin{column}{.01\textwidth}\end{column} % Empty spacer column

\end{columns} % End of all the columns in the poster

\end{frame} % End of the enclosing frame

\end{document}
